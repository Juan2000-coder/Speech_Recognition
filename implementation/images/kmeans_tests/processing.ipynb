{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROCESAMIENTO DE LAS IMAGENES DE ENTRENAMIENTO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.cluster import KMeans\n",
    "import joblib\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PATHS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path      = '../../../dataset/images'\n",
    "training_path   = os.path.join(image_path, 'training')\n",
    "original_path   = os.path.join(training_path, 'original')\n",
    "processed_path  = os.path.join(training_path, 'processed')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LISTAS DE IMAGENES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "original  = [os.path.join(original_path, image) for image in os.listdir(original_path)]\n",
    "processed  = [os.path.join(processed_path, image) for image in os.listdir(processed_path)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RANGOS DE COLOR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_red_2 = np.array([170, 60, 60])\n",
    "upper_red_2 = np.array([179, 255, 255])\n",
    "\n",
    "lower_red_1 = np.array([0, 60, 60])\n",
    "upper_red_1 = np.array([8, 255, 255])\n",
    "\n",
    "lower_orange = np.array([8, 120, 80])\n",
    "upper_orange = np.array([21, 255, 255])\n",
    "\n",
    "lower_yellow = np.array([21, 50, 80])\n",
    "upper_yellow = np.array([25, 255, 255])\n",
    "\n",
    "lower_green = np.array([25, 40, 40])\n",
    "upper_green = np.array([100, 255, 255])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROCESAMIENTO DE LAS IMAGENES**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Obtenicón de fondo blanco*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_light_background(mask, f = 20, p = 0.75):\n",
    "    height, width = mask.shape\n",
    "    cluster_size  = min([height, width])//f\n",
    "    cluster       = np.ones((cluster_size, cluster_size), np.uint8)\n",
    "\n",
    "    # Corners\n",
    "    corner1 = np.bitwise_and(cluster, mask[:cluster_size,  :cluster_size])\n",
    "    corner2 = np.bitwise_and(cluster, mask[:cluster_size:, -cluster_size:])\n",
    "    corner3 = np.bitwise_and(cluster, mask[-cluster_size:, :cluster_size])\n",
    "    corner4 = np.bitwise_and(cluster, mask[-cluster_size:, -cluster_size:])\n",
    "    corners = [corner1, corner2, corner3, corner4]\n",
    "\n",
    "    # Sides\n",
    "    limitw1 = (width - cluster_size)//2\n",
    "    limitw2 = (width + cluster_size)//2\n",
    "    limith1 = (height - cluster_size)//2\n",
    "    limith2 = (height + cluster_size)//2\n",
    "    \n",
    "    side1   = np.bitwise_and(cluster, mask[:cluster_size, limitw1:limitw2])\n",
    "    side2   = np.bitwise_and(cluster, mask[limith1:limith2, :cluster_size])\n",
    "    side3   = np.bitwise_and(cluster, mask[limith1:limith2, -cluster_size:])\n",
    "    side4   = np.bitwise_and(cluster, mask[-cluster_size:, limitw1:limitw2])\n",
    "    sides   = [side1, side2, side3, side4] \n",
    "    \n",
    "    # Determining the type of background\n",
    "    edges            = corners + sides\n",
    "    light_background = sum(np.count_nonzero(edge) for edge in edges) > p*8*(cluster_size**2)\n",
    "\n",
    "    # Inverting if dark background\n",
    "    if light_background:\n",
    "        return np.bitwise_not(mask)\n",
    "    return mask    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Procesamiento de las imagenes*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "names     = [os.path.basename(file) for file in original]\n",
    "contornos = dict.fromkeys(names)\n",
    "\n",
    "for k, file in enumerate(original):\n",
    "    # BGR image\n",
    "    image = cv2.imread(file)\n",
    "\n",
    "    # Dimentions\n",
    "    height, width, _ = image.shape\n",
    " \n",
    "    # Pixel data vector\n",
    "    data_vector = np.zeros((height * width, 4))\n",
    "\n",
    "    # Obtener matrices de color\n",
    "    rgb_matrix = image.reshape((-1, 3))\n",
    "    hsv_matrix = cv2.cvtColor(image, cv2.COLOR_BGR2HSV).reshape((-1, 3))\n",
    "    lab_matrix = cv2.cvtColor(image, cv2.COLOR_BGR2LAB).reshape((-1, 3))\n",
    "\n",
    "    # Asignar a la matriz de datos\n",
    "    data_vector[:, 0]  = rgb_matrix[:, 2]\n",
    "    data_vector[:, 1]  = hsv_matrix[:, 1]\n",
    "    data_vector[:, 2:] = lab_matrix[:, 1:]\n",
    "\n",
    "    kmeans = KMeans(n_clusters = 2, n_init = 10)  # 2 Clusters. Background and fruit\n",
    "    kmeans.fit(data_vector)\n",
    "\n",
    "    # Get clusters labels\n",
    "    labels = kmeans.labels_\n",
    "\n",
    "    # kmeans_mask\n",
    "    kmeans_mask = labels.reshape(height, width)\n",
    "    kmeans_mask = kmeans_mask.astype(np.uint8) * 255\n",
    "\n",
    "    # Determinación del tipo de fondo de la máscara\n",
    "    kmeans_mask = get_light_background(kmeans_mask)\n",
    "\n",
    "    # Erosion y dilataciòn sobre la màscara\n",
    "    erosion_size      = min([height, width])//200\n",
    "    dilatacion_size   = min([height, width])//80\n",
    "    kernel_erosion    = np.ones((erosion_size,erosion_size), np.uint8)\n",
    "    eroded            = cv2.erode(kmeans_mask, kernel_erosion, iterations = 1)\n",
    "    kernel_dilatacion = np.ones((dilatacion_size,dilatacion_size), np.uint8)\n",
    "    kmeans_mask       = cv2.dilate(eroded, kernel_dilatacion, iterations  = 2)\n",
    "\n",
    "    # Encontrar contornos\n",
    "    kmeans_cnt, _ = cv2.findContours(kmeans_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    kmeans_cnt    = max(kmeans_cnt, key = cv2.contourArea)\n",
    "    contornos[os.path.basename(file)] = kmeans_cnt\n",
    "\n",
    "    # Contorno aproximado\n",
    "    epsilon       = 0.001 * cv2.arcLength(kmeans_cnt, True)\n",
    "    kmeans_cnt    = cv2.approxPolyDP(kmeans_cnt, epsilon, True)\n",
    "    kmeans_cnt    = (kmeans_cnt,)\n",
    "\n",
    "    # Template\n",
    "    tkmeans       = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "    # Dibujar\n",
    "    cv2.drawContours(tkmeans, kmeans_cnt, -1, 255, thickness = cv2.FILLED)\n",
    "\n",
    "    # Guardar mascara\n",
    "    cv2.imwrite(os.path.join(processed_path, os.path.basename(file)), tkmeans)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gurdamos los contornos en un archivo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['contornos.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(contornos, 'contornos.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
