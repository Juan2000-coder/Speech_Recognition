{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import butter, filtfilt\n",
    "from scipy.spatial.distance import pdist, cdist\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import soundfile as sf\n",
    "from prettytable import PrettyTable\n",
    "from scipy.signal import hilbert\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.signal import hilbert, butter, filtfilt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CLASES PRINCIPALES DE LOS AUDIOS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myAudio:\n",
    "    FRAME_SIZE = 512 \n",
    "    HOP_SIZE   = 256\n",
    "    root_dir = '../../dataset/'\n",
    "\n",
    "    def __init__(self, group, basefilename):\n",
    "        self.fruit = group\n",
    "        self.original = os.path.join(self.root_dir, f\"{group}/{basefilename}\")\n",
    "        self.trimed = os.path.join(self.root_dir, f\"{group}/trimed/{basefilename}\")\n",
    "        self.type = 'original'\n",
    "        self.load()\n",
    "\n",
    "    def load(self, type:str = 'original'):\n",
    "        self.type = type\n",
    "        if type == 'trimed':\n",
    "            self.signal, self.sr = librosa.load(self.trimed, sr = None)\n",
    "            self.duration = librosa.get_duration(filename = self.trimed, sr=self.sr)\n",
    "        elif type == 'original':\n",
    "            self.signal, self.sr = librosa.load(self.original, sr = None)\n",
    "            self.duration = librosa.get_duration(filename = self.original, sr=self.sr)\n",
    "        else:\n",
    "            raise Exception(\"sos pelotudo?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myGroup:\n",
    "    def __init__(self, type:str, filenames):\n",
    "        self.type   = type\n",
    "        self.audios = [myAudio(self.type, filename) for filename in filenames if filename.endswith('.wav')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myAudios:\n",
    "    fruit_types = ['pera', 'banana', 'manzana', 'naranja']\n",
    "    root_dir = '../../dataset'\n",
    "\n",
    "    def __init__(self):\n",
    "        self.groups = []\n",
    "        self.get_paths()\n",
    "\n",
    "    def get_paths(self):\n",
    "        for dirname, _, filenames in os.walk(self.root_dir):\n",
    "            dir = os.path.basename(dirname)\n",
    "            if dir in self.fruit_types:\n",
    "                group = dir\n",
    "                self.groups.append(myGroup(group, filenames))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saqué de acá los audios ajustados en velocidad porque me di cuenta que no producián una separación clara entre grupos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**METODOS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_audio(self:myAudio, top_db):\n",
    "    if self.type != 'trimed':\n",
    "        self.signal, _ = librosa.effects.trim(self.signal, top_db = top_db, frame_length=self.FRAME_SIZE, hop_length=self.HOP_SIZE)\n",
    "        self.type = 'trimed'\n",
    "        librosa.output.write_wav(self.trimed, self.signal, sr=self.sr)\n",
    "\n",
    "myAudio.trim = trim_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_group(self:myGroup, top_db):\n",
    "    for i, _ in enumerate(self.audios):\n",
    "        self.audios[i].trim(top_db)\n",
    "myGroup.trim = trim_group"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el trim hay que empezar a probar desde 45 para abajo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Extracción de características gloabales.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_envelope(self:myAudio, cutoff_frequency = 10.0):\n",
    "    analytic_signal = hilbert(self.signal)\n",
    "    amplitude_envelope = np.abs(analytic_signal)\n",
    "\n",
    "    # Aplicar filtro pasa bajos para suavizar la envolvente\n",
    "    nyquist = 0.5 * self.sr\n",
    "    cutoff = cutoff_frequency / nyquist\n",
    "    b, a = butter(N=6, Wn=cutoff, btype='low', analog=False, output='ba')\n",
    "    \n",
    "    smoothed_envelope = filtfilt(b, a, amplitude_envelope)\n",
    "    return smoothed_envelope\n",
    "myAudio.envelope = smooth_envelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rms(self:myAudio):\n",
    "    pass\n",
    "myAudio.rms = rms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Funciones para determinar la efectividad. Distanciación entre grupos***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sphere:\n",
    "    def __init__(self, center, radius):\n",
    "        self.center = center\n",
    "        self.radius = radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_sphere(self:myGroup):\n",
    "    matrix = np.vstack([features for audio in self.audios for features = audio.features if ])\n",
    "    center = np.mean(matrix, axis = 0)\n",
    "    self.sphere = Sphere(center.reshape(1, -1), cdist(self.center, matrix).max())\n",
    "myGroup.get_sphere = group_sphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spheres(self:myAudios):\n",
    "    for i, _ in enumerate(self.groups):\n",
    "        self.groups[i].get_sphere()\n",
    "myAudios.get_spheres = get_spheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_overlaps(self:myAudios):\n",
    "    centers = get_centers(fruit_features)\n",
    "    radiuses = get_radiuses(fruit_features)\n",
    "    overlaps = dict.fromkeys(fruit_features.keys())\n",
    "    \n",
    "    # A dictionary of dictionarys. Keys, the fruit types\n",
    "    for key in overlaps:\n",
    "        # Each dictionary in the dictionary\n",
    "        overlaps[key] = dict.fromkeys(fruit_types)\n",
    "    \n",
    "    for i in range(len(fruit_types)):\n",
    "        for j in range(i + 1, len(fruit_types)):\n",
    "            distancesAB = cdist(centers[fruit_types[i]], fruit_features[fruit_types[j]])\n",
    "            distancesBA = cdist(centers[fruit_types[j]], fruit_features[fruit_types[i]])\n",
    "\n",
    "            mask_distancesAB = distancesAB < radiuses[fruit_types[i]]\n",
    "            mask_distancesBA = distancesBA < radiuses[fruit_types[j]]\n",
    "\n",
    "            numberBinA = np.count_nonzero(mask_distancesAB)\n",
    "            numberAinB = np.count_nonzero(mask_distancesBA)\n",
    "\n",
    "            overlaps[fruit_types[i]][fruit_types[j]] = numberBinA\n",
    "            overlaps[fruit_types[j]][fruit_types[i]] = numberAinB\n",
    "    return overlaps # Each element is the number of vectors of one group in the sphere of another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_components(centers, nc):\n",
    "    pacum = np.zeros((1, centers[fruit_types[0]].shape[1]))\n",
    "    pair_components = dict()\n",
    "    for i in range(len(fruit_types)):\n",
    "        for j in range(i + 1, len(fruit_types)):\n",
    "            dif = centers[fruit_types[i]] - centers[fruit_types[j]]\n",
    "            dist = cdist(centers[fruit_types[i]], centers[fruit_types[j]])\n",
    "            difp = (dif**2)*100/(dist**2)\n",
    "            pair_components[f\"{fruit_types[i]}-{fruit_types[j]}\"]= np.argsort(difp[0])[-nc:]\n",
    "            pacum += difp\n",
    "    index_max = np.argsort(pacum[0])[-nc:]\n",
    "    #return np.sort(index_max)\n",
    "    return index_max, pair_components"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PRINCIPAL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(training, test, k_n):\n",
    "    X = np.concatenate([v for v in training.values()], axis=0)\n",
    "    y = np.concatenate([[k] * v.shape[0] for k, v in training.items()])\n",
    "\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Crear clasificador KNN\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors = k_n)\n",
    "\n",
    "    # Entrenar el clasificador\n",
    "    knn_classifier.fit(X, y)\n",
    "\n",
    "    # Predecir las etiquetas para los datos de prueba\n",
    "    predicted_fruit = knn_classifier.predict(test)\n",
    "\n",
    "    print(f'La fruta predicha para el nuevo audio es: {predicted_fruit[0]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PLOTEO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2d\n",
    "fig = plt.figure()\n",
    "\n",
    "colors = dict(zip(fruit_types,['green','yellow','red','orange']))\n",
    "center_colors  = dict(zip(fruit_types,['blue','brown','black','cyan']))\n",
    "\n",
    "for fruit, points in features.items():\n",
    "    plt.scatter(points[:, 0], points[:, 1], c = colors[fruit], label=fruit)\n",
    "\n",
    "plt.xlabel('Eje X')\n",
    "plt.ylabel('Eje Y')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3d\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "for fruit, points in features.items():\n",
    "    ax.scatter(points[:, 0], points[:, 1], points[:, 2], c=colors[fruit], marker='o', label=fruit)\n",
    "    #ax.scatter(centers[fruit][:, 0], centers[fruit][:, 1], centers[fruit][:, 2], c=center_colors[fruit], marker='o', label=f\"{fruit}-center\")\n",
    "\n",
    "# configure labels\n",
    "ax.set_xlabel('Eje X')\n",
    "ax.set_ylabel('Eje Y')\n",
    "ax.set_zlabel('Eje Z')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import butter, filtfilt\n",
    "from scipy.spatial.distance import pdist, cdist\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import soundfile as sf\n",
    "from prettytable import PrettyTable\n",
    "from scipy.signal import hilbert\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.signal import hilbert, butter, filtfilt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CLASES PRINCIPALES DE LOS AUDIOS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myAudio:\n",
    "    FRAME_SIZE = 512 \n",
    "    HOP_SIZE   = 256\n",
    "    root_dir = '../../dataset/'\n",
    "\n",
    "    def __init__(self, group, basefilename):\n",
    "        self.fruit = group\n",
    "        self.original = os.path.join(self.root_dir, f\"{group}/{basefilename}\")\n",
    "        self.trimed = os.path.join(self.root_dir, f\"{group}/trimed/{basefilename}\")\n",
    "        self.type = 'original'\n",
    "        self.load()\n",
    "\n",
    "    def load(self, type:str = 'original'):\n",
    "        self.type = type\n",
    "        if type == 'trimed':\n",
    "            self.signal, self.sr = librosa.load(self.trimed, sr = None)\n",
    "            self.duration = librosa.get_duration(filename = self.trimed, sr=self.sr)\n",
    "        elif type == 'original':\n",
    "            self.signal, self.sr = librosa.load(self.original, sr = None)\n",
    "            self.duration = librosa.get_duration(filename = self.original, sr=self.sr)\n",
    "        else:\n",
    "            raise Exception(\"sos pelotudo?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myGroup:\n",
    "    def __init__(self, type:str, filenames):\n",
    "        self.type   = type\n",
    "        self.audios = [myAudio(self.type, filename) for filename in filenames if filename.endswith('.wav')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myAudios:\n",
    "    fruit_types = ['pera', 'banana', 'manzana', 'naranja']\n",
    "    root_dir = '../../dataset'\n",
    "\n",
    "    def __init__(self):\n",
    "        self.groups = []\n",
    "        self.get_paths()\n",
    "\n",
    "    def get_paths(self):\n",
    "        for dirname, _, filenames in os.walk(self.root_dir):\n",
    "            dir = os.path.basename(dirname)\n",
    "            if dir in self.fruit_types:\n",
    "                group = dir\n",
    "                self.groups.append(myGroup(group, filenames))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saqué de acá los audios ajustados en velocidad porque me di cuenta que no producián una separación clara entre grupos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**METODOS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_audio(self:myAudio, top_db):\n",
    "    if self.type != 'trimed':\n",
    "        self.signal, _ = librosa.effects.trim(self.signal, top_db = top_db, frame_length=self.FRAME_SIZE, hop_length=self.HOP_SIZE)\n",
    "        self.type = 'trimed'\n",
    "        librosa.output.write_wav(self.trimed, self.signal, sr=self.sr)\n",
    "\n",
    "myAudio.trim = trim_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_group(self:myGroup, top_db):\n",
    "    for i, _ in enumerate(self.audios):\n",
    "        self.audios[i].trim(top_db)\n",
    "myGroup.trim = trim_group"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el trim hay que empezar a probar desde 45 para abajo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Extracción de características gloabales.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_envelope(self:myAudio, cutoff_frequency = 10.0):\n",
    "    analytic_signal = hilbert(self.signal)\n",
    "    amplitude_envelope = np.abs(analytic_signal)\n",
    "\n",
    "    # Aplicar filtro pasa bajos para suavizar la envolvente\n",
    "    nyquist = 0.5 * self.sr\n",
    "    cutoff = cutoff_frequency / nyquist\n",
    "    b, a = butter(N=6, Wn=cutoff, btype='low', analog=False, output='ba')\n",
    "    \n",
    "    smoothed_envelope = filtfilt(b, a, amplitude_envelope)\n",
    "    return smoothed_envelope\n",
    "myAudio.envelope = smooth_envelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rms(self:myAudio):\n",
    "    pass\n",
    "myAudio.rms = rms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Funciones para determinar la efectividad. Distanciación entre grupos***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sphere:\n",
    "    def __init__(self, center, radius):\n",
    "        self.center = center\n",
    "        self.radius = radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_sphere(self:myGroup):\n",
    "    matrix = np.vstack([features for audio in self.audios for features = audio.features if ])\n",
    "    center = np.mean(matrix, axis = 0)\n",
    "    self.sphere = Sphere(center.reshape(1, -1), cdist(self.center, matrix).max())\n",
    "myGroup.get_sphere = group_sphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spheres(self:myAudios):\n",
    "    for i, _ in enumerate(self.groups):\n",
    "        self.groups[i].get_sphere()\n",
    "myAudios.get_spheres = get_spheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_overlaps(self:myAudios):\n",
    "    centers = get_centers(fruit_features)\n",
    "    radiuses = get_radiuses(fruit_features)\n",
    "    overlaps = dict.fromkeys(fruit_features.keys())\n",
    "    \n",
    "    # A dictionary of dictionarys. Keys, the fruit types\n",
    "    for key in overlaps:\n",
    "        # Each dictionary in the dictionary\n",
    "        overlaps[key] = dict.fromkeys(fruit_types)\n",
    "    \n",
    "    for i in range(len(fruit_types)):\n",
    "        for j in range(i + 1, len(fruit_types)):\n",
    "            distancesAB = cdist(centers[fruit_types[i]], fruit_features[fruit_types[j]])\n",
    "            distancesBA = cdist(centers[fruit_types[j]], fruit_features[fruit_types[i]])\n",
    "\n",
    "            mask_distancesAB = distancesAB < radiuses[fruit_types[i]]\n",
    "            mask_distancesBA = distancesBA < radiuses[fruit_types[j]]\n",
    "\n",
    "            numberBinA = np.count_nonzero(mask_distancesAB)\n",
    "            numberAinB = np.count_nonzero(mask_distancesBA)\n",
    "\n",
    "            overlaps[fruit_types[i]][fruit_types[j]] = numberBinA\n",
    "            overlaps[fruit_types[j]][fruit_types[i]] = numberAinB\n",
    "    return overlaps # Each element is the number of vectors of one group in the sphere of another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_components(centers, nc):\n",
    "    pacum = np.zeros((1, centers[fruit_types[0]].shape[1]))\n",
    "    pair_components = dict()\n",
    "    for i in range(len(fruit_types)):\n",
    "        for j in range(i + 1, len(fruit_types)):\n",
    "            dif = centers[fruit_types[i]] - centers[fruit_types[j]]\n",
    "            dist = cdist(centers[fruit_types[i]], centers[fruit_types[j]])\n",
    "            difp = (dif**2)*100/(dist**2)\n",
    "            pair_components[f\"{fruit_types[i]}-{fruit_types[j]}\"]= np.argsort(difp[0])[-nc:]\n",
    "            pacum += difp\n",
    "    index_max = np.argsort(pacum[0])[-nc:]\n",
    "    #return np.sort(index_max)\n",
    "    return index_max, pair_components"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PRINCIPAL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(training, test, k_n):\n",
    "    X = np.concatenate([v for v in training.values()], axis=0)\n",
    "    y = np.concatenate([[k] * v.shape[0] for k, v in training.items()])\n",
    "\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Crear clasificador KNN\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors = k_n)\n",
    "\n",
    "    # Entrenar el clasificador\n",
    "    knn_classifier.fit(X, y)\n",
    "\n",
    "    # Predecir las etiquetas para los datos de prueba\n",
    "    predicted_fruit = knn_classifier.predict(test)\n",
    "\n",
    "    print(f'La fruta predicha para el nuevo audio es: {predicted_fruit[0]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PLOTEO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2d\n",
    "fig = plt.figure()\n",
    "\n",
    "colors = dict(zip(fruit_types,['green','yellow','red','orange']))\n",
    "center_colors  = dict(zip(fruit_types,['blue','brown','black','cyan']))\n",
    "\n",
    "for fruit, points in features.items():\n",
    "    plt.scatter(points[:, 0], points[:, 1], c = colors[fruit], label=fruit)\n",
    "\n",
    "plt.xlabel('Eje X')\n",
    "plt.ylabel('Eje Y')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3d\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "for fruit, points in features.items():\n",
    "    ax.scatter(points[:, 0], points[:, 1], points[:, 2], c=colors[fruit], marker='o', label=fruit)\n",
    "    #ax.scatter(centers[fruit][:, 0], centers[fruit][:, 1], centers[fruit][:, 2], c=center_colors[fruit], marker='o', label=f\"{fruit}-center\")\n",
    "\n",
    "# configure labels\n",
    "ax.set_xlabel('Eje X')\n",
    "ax.set_ylabel('Eje Y')\n",
    "ax.set_zlabel('Eje Z')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
