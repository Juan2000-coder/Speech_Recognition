{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import pdist, cdist\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import soundfile as sf\n",
    "from prettytable import PrettyTable\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.signal import hilbert, butter, filtfilt, medfilt, lfilter, wiener, convolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_types = ['pera', 'banana', 'manzana', 'naranja']\n",
    "audios = {fruit: [] for fruit in fruit_types}\n",
    "root_dir = '../../dataset'\n",
    "\n",
    "for dirname, _, filenames in os.walk(root_dir):\n",
    "    fruit_type = os.path.basename(dirname)\n",
    "    if fruit_type in fruit_types:\n",
    "        audios[fruit_type].extend([os.path.join(dirname, filename) for filename in filenames if filename.endswith('.wav')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = {fruit: [] for fruit in fruit_types}\n",
    "\n",
    "for dirname, _, filenames in os.walk(root_dir):\n",
    "    path = os.path.basename(dirname)\n",
    "    if path == 'processed':\n",
    "        fruit_type = os.path.basename(os.path.dirname(dirname))\n",
    "        if fruit_type in fruit_types:\n",
    "            processed[fruit_type].extend([os.path.join(dirname, filename) for filename in filenames if filename.endswith('.wav')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAME_SIZE = 512 # In the documentation says it's convenient for speech.C\n",
    "HOP_SIZE   = int(FRAME_SIZE/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio(audiofile):\n",
    "    test_audio, sr = librosa.load(audiofile, sr = None)\n",
    "    duration = librosa.get_duration(filename=audiofile, sr=sr)\n",
    "    return test_audio, sr, duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_vector(signal, duration):\n",
    "    return np.linspace(0, duration, len(signal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rms(signal):\n",
    "    return librosa.feature.rms(y=signal, frame_length = FRAME_SIZE, hop_length = HOP_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(signal):\n",
    "    peak = np.max(signal)\n",
    "    signal/=peak\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def low_pass_filter(signal, sr, cutoff_frequency = 5000):\n",
    "    nyquist = 0.5 * sr\n",
    "    cutoff = cutoff_frequency / nyquist\n",
    "    b, a = butter(N=6, Wn=cutoff, btype='low', analog=False, output='ba')\n",
    "    filtered = lfilter(b, a, signal)\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def envelope(signal):\n",
    "    analytic_signal = hilbert(signal)\n",
    "    return np.abs(analytic_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_envelope(signal, sr, cutoff_frequency=10.0):\n",
    "    return low_pass_filter(envelope(signal), sr, cutoff_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(training, test, k_n):\n",
    "    X = np.concatenate([v for v in training.values()], axis=0)\n",
    "    y = np.concatenate([[k] * v.shape[0] for k, v in training.items()])\n",
    "\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Crear clasificador KNN\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors = k_n)\n",
    "\n",
    "    # Entrenar el clasificador\n",
    "    knn_classifier.fit(X, y)\n",
    "\n",
    "    # Predecir las etiquetas para los datos de prueba\n",
    "    predicted_fruit = knn_classifier.predict(test)\n",
    "\n",
    "    print(f'La fruta predicha para el nuevo audio es: {predicted_fruit[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2d\n",
    "def plot_features2d(features):\n",
    "    fig = plt.figure()\n",
    "    colors = dict(zip(fruit_types,['green','yellow','red','orange']))\n",
    "    \n",
    "\n",
    "    for fruit, points in features.items():\n",
    "        plt.scatter(points[:, 0], points[:, 1], c = colors[fruit], label=fruit)\n",
    "\n",
    "    plt.xlabel('Eje X')\n",
    "    plt.ylabel('Eje Y')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3d\n",
    "def plot_features3D(features:dict):\n",
    "    fig = plt.figure()\n",
    "    colors = dict(zip(fruit_types,['green','yellow','red','orange']))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    for fruit, points in features.items():\n",
    "        ax.scatter(points[:, 0], points[:, 1], points[:, 2], c=colors[fruit], marker='o', label=fruit)\n",
    "        #ax.scatter(centers[fruit][:, 0], centers[fruit][:, 1], centers[fruit][:, 2], c=center_colors[fruit], marker='o', label=f\"{fruit}-center\")\n",
    "\n",
    "    # configure labels\n",
    "    ax.set_xlabel('Eje X')\n",
    "    ax.set_ylabel('Eje Y')\n",
    "    ax.set_zlabel('Eje Z')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_split_frequency_bin(split_frequency, sample_rate, num_frequency_bins):\n",
    "    \"\"\"Infer the frequency bin associated to a given split frequency.\"\"\"\n",
    "    \n",
    "    frequency_range = sample_rate / 2\n",
    "    frequency_delta_per_bin = frequency_range / num_frequency_bins\n",
    "    split_frequency_bin = math.floor(split_frequency / frequency_delta_per_bin)\n",
    "    return int(split_frequency_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def band_energy_ratio(spectrogram, split_frequency, sample_rate):\n",
    "    \"\"\"Calculate band energy ratio with a given split frequency.\"\"\"\n",
    "    \n",
    "    split_frequency_bin = calculate_split_frequency_bin(split_frequency, sample_rate, len(spectrogram[0]))\n",
    "    band_energy_ratio = []\n",
    "    \n",
    "    # calculate power spectrogram\n",
    "    power_spectrogram = np.abs(spectrogram) ** 2\n",
    "    power_spectrogram = power_spectrogram.T\n",
    "    \n",
    "    # calculate BER value for each frame\n",
    "    for frame in power_spectrogram:\n",
    "        sum_power_low_frequencies = frame[:split_frequency_bin].sum()\n",
    "        sum_power_high_frequencies = frame[split_frequency_bin:].sum()\n",
    "        band_energy_ratio_current_frame = sum_power_low_frequencies / sum_power_high_frequencies\n",
    "        band_energy_ratio.append(band_energy_ratio_current_frame)\n",
    "    \n",
    "    return np.array(band_energy_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 2000\n",
    "features = dict.fromkeys(fruit_types)\n",
    "split_frequency = 2000\n",
    "\n",
    "# Extracción de características\n",
    "for fruit, group in processed.items():\n",
    "    features[fruit] = None\n",
    "    for audio in group:\n",
    "        signal, sr, duration = load_audio(audio)\n",
    "        audio_rms = np.sqrt(np.mean(signal**2))/np.max(signal)\n",
    "\n",
    "        spec = librosa.stft(signal, n_fft = FRAME_SIZE, hop_length = HOP_SIZE)\n",
    "        BER  = band_energy_ratio(spec, split_frequency, sr)\n",
    "        BER /= np.max(BER)\n",
    "        feat = np.mean(BER)\n",
    "\n",
    "        #centroidal = librosa.feature.spectral_centroid(y=signal, sr=sr, n_fft=FRAME_SIZE, hop_length=HOP_SIZE)[0]\n",
    "        #centroidal /= np.max(centroidal)\n",
    "        #centroidal = np.mean(centroidal)\n",
    "        #smoothed = rms(signal)\n",
    "        #smoothed = smoothed.reshape(-1,)\n",
    "        #rms_smoothed = np.mean(smoothed)/np.max(smoothed)\n",
    "        #filtered = low_pass_filter(signal, sr, cutoff)\n",
    "        #feat = librosa.feature.zero_crossing_rate(signal, frame_length=FRAME_SIZE, hop_length=HOP_SIZE)[0]\n",
    "        #max = np.max(zcr)\n",
    "        #flux = spectral_flux(filtered)\n",
    "        #max = np.max(flux)\n",
    "        #flux /= max\n",
    "        #flux = np.mean(flux)\n",
    "        #roll_off = librosa.feature.spectral_rolloff(y=signal, sr=sr, n_fft=FRAME_SIZE, hop_length=HOP_SIZE, roll_percent=0.85)[0]\n",
    "        #max = np.max(roll_off)\n",
    "        #roll_off /= max\n",
    "        #roll_off = np.mean(roll_off)\n",
    "        #smoothed /= np.max(smoothed)\n",
    "        #N = 1\n",
    "        #feat = librosa.feature.mfcc(y = signal, sr=sr, n_mfcc = 5, n_fft = FRAME_SIZE, hop_length = HOP_SIZE)\n",
    "        #feat = librosa.feature.delta(feat, order = 3)\n",
    "\n",
    "        #frames = range(len(feat))\n",
    "        #t = librosa.frames_to_time(frames, sr=sr, n_fft = FRAME_SIZE, hop_length=HOP_SIZE)\n",
    "\n",
    "        #absolute = np.abs(feat)\n",
    "        #feat /= np.max(absolute)\n",
    "        #absolute /= np.max(absolute)\n",
    "        #feat = np.abs(feat)\n",
    "        #row = feat[N,:]\n",
    "        #row = np.abs(row)\n",
    "\n",
    "        #momentum = np.dot(t, absolute)\n",
    "        #momentum/=np.sum(absolute)\n",
    "        #means = np.mean(feat)\n",
    "\n",
    "        feature = np.array([[audio_rms, feat]])\n",
    "        if features[fruit] is not None:\n",
    "            features[fruit] = np.vstack([features[fruit], feature])\n",
    "        else:\n",
    "            features[fruit] = feature\n",
    "# Ploteo\n",
    "plot_features2d(features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BER**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Con la media del BER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 2000\n",
    "features = dict.fromkeys(fruit_types)\n",
    "split_frequency = 2000\n",
    "\n",
    "# Extracción de características\n",
    "for fruit, group in processed.items():\n",
    "    features[fruit] = None\n",
    "    for audio in group:\n",
    "        signal, sr, duration = load_audio(audio)\n",
    "        audio_rms = np.sqrt(np.mean(signal**2))/np.max(signal)\n",
    "\n",
    "        spec = librosa.stft(signal, n_fft = FRAME_SIZE, hop_length = HOP_SIZE)\n",
    "        BER  = band_energy_ratio(spec, split_frequency, sr)\n",
    "        BER /= np.max(np.abs(BER))\n",
    "        feat = np.mean(BER)\n",
    "        \n",
    "        feature = np.array([[audio_rms, feat]])\n",
    "        if features[fruit] is not None:\n",
    "            features[fruit] = np.vstack([features[fruit], feature])\n",
    "        else:\n",
    "            features[fruit] = feature\n",
    "# Ploteo\n",
    "plot_features2d(features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Con el RMS del BER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 2000\n",
    "features = dict.fromkeys(fruit_types)\n",
    "split_frequency = 2000\n",
    "\n",
    "# Extracción de características\n",
    "for fruit, group in processed.items():\n",
    "    features[fruit] = None\n",
    "    for audio in group:\n",
    "        signal, sr, duration = load_audio(audio)\n",
    "        audio_rms = np.sqrt(np.mean(signal**2))/np.max(signal)\n",
    "\n",
    "        spec = librosa.stft(signal, n_fft = FRAME_SIZE, hop_length = HOP_SIZE)\n",
    "        BER  = band_energy_ratio(spec, split_frequency, sr)\n",
    "        BER /= np.max(np.abs(BER))\n",
    "        feat = np.sqrt(np.mean(BER**2))/np.max(BER)\n",
    "        \n",
    "        feature = np.array([[audio_rms, feat]])\n",
    "        if features[fruit] is not None:\n",
    "            features[fruit] = np.vstack([features[fruit], feature])\n",
    "        else:\n",
    "            features[fruit] = feature\n",
    "# Ploteo\n",
    "plot_features2d(features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Con el maximo del BER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 2000\n",
    "features = dict.fromkeys(fruit_types)\n",
    "split_frequency = 2000\n",
    "\n",
    "# Extracción de características\n",
    "for fruit, group in processed.items():\n",
    "    features[fruit] = None\n",
    "    for audio in group:\n",
    "        signal, sr, duration = load_audio(audio)\n",
    "        audio_rms = np.sqrt(np.mean(signal**2))/np.max(signal)\n",
    "\n",
    "        spec = librosa.stft(signal, n_fft = FRAME_SIZE, hop_length = HOP_SIZE)\n",
    "        BER  = band_energy_ratio(spec, split_frequency, sr)\n",
    "        feat = np.max(BER)\n",
    "        \n",
    "        feature = np.array([[audio_rms, feat]])\n",
    "        if features[fruit] is not None:\n",
    "            features[fruit] = np.vstack([features[fruit], feature])\n",
    "        else:\n",
    "            features[fruit] = feature\n",
    "# Ploteo\n",
    "plot_features2d(features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Con el mínimo del BER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 2000\n",
    "features = dict.fromkeys(fruit_types)\n",
    "split_frequency = 2000\n",
    "\n",
    "# Extracción de características\n",
    "for fruit, group in processed.items():\n",
    "    features[fruit] = None\n",
    "    for audio in group:\n",
    "        signal, sr, duration = load_audio(audio)\n",
    "        audio_rms = np.sqrt(np.mean(signal**2))/np.max(signal)\n",
    "\n",
    "        spec = librosa.stft(signal, n_fft = FRAME_SIZE, hop_length = HOP_SIZE)\n",
    "        BER  = band_energy_ratio(spec, split_frequency, sr)\n",
    "        feat = np.min(BER)\n",
    "        \n",
    "        feature = np.array([[audio_rms, feat]])\n",
    "        if features[fruit] is not None:\n",
    "            features[fruit] = np.vstack([features[fruit], feature])\n",
    "        else:\n",
    "            features[fruit] = feature\n",
    "# Ploteo\n",
    "plot_features2d(features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Con la varianza del BER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 2000\n",
    "features = dict.fromkeys(fruit_types)\n",
    "split_frequency = 2000\n",
    "\n",
    "# Extracción de características\n",
    "for fruit, group in processed.items():\n",
    "    features[fruit] = None\n",
    "    for audio in group:\n",
    "        signal, sr, duration = load_audio(audio)\n",
    "        audio_rms = np.sqrt(np.mean(signal**2))/np.max(signal)\n",
    "\n",
    "        spec = librosa.stft(signal, n_fft = FRAME_SIZE, hop_length = HOP_SIZE)\n",
    "        BER  = band_energy_ratio(spec, split_frequency, sr)\n",
    "        #BER /= np.max(BER)\n",
    "        feat = np.var(BER)\n",
    "        \n",
    "        feature = np.array([[audio_rms, feat]])\n",
    "        if features[fruit] is not None:\n",
    "            features[fruit] = np.vstack([features[fruit], feature])\n",
    "        else:\n",
    "            features[fruit] = feature\n",
    "# Ploteo\n",
    "plot_features2d(features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Con la desviación estándar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 2000\n",
    "features = dict.fromkeys(fruit_types)\n",
    "split_frequency = 2000\n",
    "\n",
    "# Extracción de características\n",
    "for fruit, group in processed.items():\n",
    "    features[fruit] = None\n",
    "    for audio in group:\n",
    "        signal, sr, duration = load_audio(audio)\n",
    "        audio_rms = np.sqrt(np.mean(signal**2))/np.max(signal)\n",
    "\n",
    "        spec = librosa.stft(signal, n_fft = FRAME_SIZE, hop_length = HOP_SIZE)\n",
    "        BER  = band_energy_ratio(spec, split_frequency, sr)\n",
    "        BER /= np.max(BER)\n",
    "        feat = np.std(BER)\n",
    "        \n",
    "        feature = np.array([[audio_rms, feat]])\n",
    "        if features[fruit] is not None:\n",
    "            features[fruit] = np.vstack([features[fruit], feature])\n",
    "        else:\n",
    "            features[fruit] = feature\n",
    "# Ploteo\n",
    "plot_features2d(features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Con el momento sin la suma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 2000\n",
    "features = dict.fromkeys(fruit_types)\n",
    "split_frequency = 2000\n",
    "\n",
    "# Extracción de características\n",
    "for fruit, group in processed.items():\n",
    "    features[fruit] = None\n",
    "    for audio in group:\n",
    "        signal, sr, duration = load_audio(audio)\n",
    "        audio_rms = np.sqrt(np.mean(signal**2))/np.max(signal)\n",
    "\n",
    "        spec = librosa.stft(signal, n_fft = FRAME_SIZE, hop_length = HOP_SIZE)\n",
    "        BER  = band_energy_ratio(spec, split_frequency, sr)\n",
    "        BER /= np.max(np.abs(BER))\n",
    "        frames = range(len(BER))\n",
    "        t = librosa.frames_to_time(frames, sr=sr, hop_length=HOP_SIZE, n_fft = FRAME_SIZE)\n",
    "\n",
    "        feat = np.dot(BER, t)\n",
    "        \n",
    "        feature = np.array([[audio_rms, feat]])\n",
    "        if features[fruit] is not None:\n",
    "            features[fruit] = np.vstack([features[fruit], feature])\n",
    "        else:\n",
    "            features[fruit] = feature\n",
    "# Ploteo\n",
    "plot_features2d(features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Con el momento con suma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 2000\n",
    "features = dict.fromkeys(fruit_types)\n",
    "split_frequency = 2000\n",
    "\n",
    "# Extracción de características\n",
    "for fruit, group in processed.items():\n",
    "    features[fruit] = None\n",
    "    for audio in group:\n",
    "        signal, sr, duration = load_audio(audio)\n",
    "        audio_rms = np.sqrt(np.mean(signal**2))/np.max(signal)\n",
    "\n",
    "        spec = librosa.stft(signal, n_fft = FRAME_SIZE, hop_length = HOP_SIZE)\n",
    "        BER  = band_energy_ratio(spec, split_frequency, sr)\n",
    "        BER /= np.max(np.abs(BER))\n",
    "        frames = range(len(BER))\n",
    "        t = librosa.frames_to_time(frames, sr=sr, hop_length=HOP_SIZE, n_fft = FRAME_SIZE)\n",
    "\n",
    "        feat = np.dot(BER, t)/np.sum(BER)\n",
    "        \n",
    "        feature = np.array([[audio_rms, feat]])\n",
    "        if features[fruit] is not None:\n",
    "            features[fruit] = np.vstack([features[fruit], feature])\n",
    "        else:\n",
    "            features[fruit] = feature\n",
    "# Ploteo\n",
    "plot_features2d(features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Con el momento del valor absoluto sin suma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 2000\n",
    "features = dict.fromkeys(fruit_types)\n",
    "split_frequency = 2000\n",
    "\n",
    "# Extracción de características\n",
    "for fruit, group in processed.items():\n",
    "    features[fruit] = None\n",
    "    for audio in group:\n",
    "        signal, sr, duration = load_audio(audio)\n",
    "        audio_rms = np.sqrt(np.mean(signal**2))/np.max(signal)\n",
    "\n",
    "        spec = librosa.stft(signal, n_fft = FRAME_SIZE, hop_length = HOP_SIZE)\n",
    "        BER  = band_energy_ratio(spec, split_frequency, sr)\n",
    "        BER /= np.max(np.abs(BER))\n",
    "        frames = range(len(BER))\n",
    "        t = librosa.frames_to_time(frames, sr=sr, hop_length=HOP_SIZE, n_fft = FRAME_SIZE)\n",
    "\n",
    "        feat = np.dot(np.abs(BER), t)\n",
    "        \n",
    "        feature = np.array([[audio_rms, feat]])\n",
    "        if features[fruit] is not None:\n",
    "            features[fruit] = np.vstack([features[fruit], feature])\n",
    "        else:\n",
    "            features[fruit] = feature\n",
    "# Ploteo\n",
    "plot_features2d(features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Con el momentum del BER en abs y la suma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 2000\n",
    "features = dict.fromkeys(fruit_types)\n",
    "split_frequency = 2000\n",
    "\n",
    "# Extracción de características\n",
    "for fruit, group in processed.items():\n",
    "    features[fruit] = None\n",
    "    for audio in group:\n",
    "        signal, sr, duration = load_audio(audio)\n",
    "        audio_rms = np.sqrt(np.mean(signal**2))/np.max(signal)\n",
    "\n",
    "        spec = librosa.stft(signal, n_fft = FRAME_SIZE, hop_length = HOP_SIZE)\n",
    "        BER  = band_energy_ratio(spec, split_frequency, sr)\n",
    "        BER /= np.max(np.abs(BER))\n",
    "        frames = range(len(BER))\n",
    "        t = librosa.frames_to_time(frames, sr=sr, hop_length=HOP_SIZE, n_fft = FRAME_SIZE)\n",
    "\n",
    "        feat = np.dot(np.abs(BER), t)/np.sum(np.abs(BER))\n",
    "        \n",
    "        feature = np.array([[audio_rms, feat]])\n",
    "        if features[fruit] is not None:\n",
    "            features[fruit] = np.vstack([features[fruit], feature])\n",
    "        else:\n",
    "            features[fruit] = feature\n",
    "# Ploteo\n",
    "plot_features2d(features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
