{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import pdist, cdist\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import soundfile as sf\n",
    "from prettytable import PrettyTable\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.signal import hilbert, butter, filtfilt, medfilt, lfilter, wiener, convolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_types = ['pera', 'banana', 'manzana', 'naranja']\n",
    "audios = {fruit: [] for fruit in fruit_types}\n",
    "root_dir = '../../dataset'\n",
    "\n",
    "for dirname, _, filenames in os.walk(root_dir):\n",
    "    fruit_type = os.path.basename(dirname)\n",
    "    if fruit_type in fruit_types:\n",
    "        audios[fruit_type].extend([os.path.join(dirname, filename) for filename in filenames if filename.endswith('.wav')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = {fruit: [] for fruit in fruit_types}\n",
    "\n",
    "for dirname, _, filenames in os.walk(root_dir):\n",
    "    path = os.path.basename(dirname)\n",
    "    if path == 'processed':\n",
    "        fruit_type = os.path.basename(os.path.dirname(dirname))\n",
    "        if fruit_type in fruit_types:\n",
    "            processed[fruit_type].extend([os.path.join(dirname, filename) for filename in filenames if filename.endswith('.wav')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAME_SIZE = 2048 # In the documentation says it's convenient for speech.C\n",
    "HOP_SIZE   = int(FRAME_SIZE/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio(audiofile):\n",
    "    test_audio, sr = librosa.load(audiofile, sr = None)\n",
    "    duration = librosa.get_duration(filename=audiofile, sr=sr)\n",
    "    return test_audio, sr, duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_vector(signal, duration):\n",
    "    return np.linspace(0, duration, len(signal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rms(signal):\n",
    "    return librosa.feature.rms(y=signal, frame_length = FRAME_SIZE, hop_length = HOP_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(signal):\n",
    "    peak = np.max(signal)\n",
    "    signal/=peak\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def low_pass_filter(signal, sr, cutoff_frequency = 5000):\n",
    "    nyquist = 0.5 * sr\n",
    "    cutoff = cutoff_frequency / nyquist\n",
    "    b, a = butter(N=6, Wn=cutoff, btype='low', analog=False, output='ba')\n",
    "    filtered = lfilter(b, a, signal)\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def envelope(signal):\n",
    "    analytic_signal = hilbert(signal)\n",
    "    return np.abs(analytic_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_envelope(signal, sr, cutoff_frequency=50.0):\n",
    "    return low_pass_filter(envelope(signal), sr, cutoff_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2d\n",
    "def plot_features2d(features):\n",
    "    fig = plt.figure()\n",
    "    colors = dict(zip(fruit_types,['green','yellow','red','orange']))\n",
    "    \n",
    "\n",
    "    for fruit, points in features.items():\n",
    "        plt.scatter(points[:, 0], points[:, 1], c = colors[fruit], label=fruit)\n",
    "\n",
    "    plt.xlabel('Eje X')\n",
    "    plt.ylabel('Eje Y')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 2000\n",
    "features = dict.fromkeys(fruit_types)\n",
    "split_frequency = 2000\n",
    "\n",
    "# Extracción de características\n",
    "for fruit, group in processed.items():\n",
    "    features[fruit] = None\n",
    "    for audio in group:\n",
    "        signal, sr, duration = load_audio(audio)\n",
    "        audio_rms = np.sqrt(np.mean(signal**2))/np.max(signal)\n",
    "\n",
    "        #spec = librosa.stft(signal, n_fft = FRAME_SIZE, hop_length = HOP_SIZE)\n",
    "        #BER  = band_energy_ratio(spec, split_frequency, sr)\n",
    "        #BER /= np.max(BER)\n",
    "        #feat = np.mean(BER)\n",
    "\n",
    "        #centroidal = librosa.feature.spectral_centroid(y=signal, sr=sr, n_fft=FRAME_SIZE, hop_length=HOP_SIZE)[0]\n",
    "        #centroidal /= np.max(centroidal)\n",
    "        #centroidal = np.mean(centroidal)\n",
    "        #smoothed = rms(signal)\n",
    "        #smoothed = smoothed.reshape(-1,)\n",
    "        #rms_smoothed = np.mean(smoothed)/np.max(smoothed)\n",
    "        #filtered = low_pass_filter(signal, sr, cutoff)\n",
    "        #feat = librosa.feature.zero_crossing_rate(signal, frame_length=FRAME_SIZE, hop_length=HOP_SIZE)[0]\n",
    "        #max = np.max(zcr)\n",
    "        #flux = spectral_flux(filtered)\n",
    "        #max = np.max(flux)\n",
    "        #flux /= max\n",
    "        #flux = np.mean(flux)\n",
    "        #roll_off = librosa.feature.spectral_rolloff(y=signal, sr=sr, n_fft=FRAME_SIZE, hop_length=HOP_SIZE, roll_percent=0.85)[0]\n",
    "        #max = np.max(roll_off)\n",
    "        #roll_off /= max\n",
    "        #roll_off = np.mean(roll_off)\n",
    "        #smoothed /= np.max(smoothed)\n",
    "        #N = 1\n",
    "        #feat = librosa.feature.mfcc(y = signal, sr=sr, n_mfcc = 5, n_fft = FRAME_SIZE, hop_length = HOP_SIZE)\n",
    "        #feat = librosa.feature.delta(feat, order = 3)\n",
    "\n",
    "        #frames = range(len(feat))\n",
    "        #t = librosa.frames_to_time(frames, sr=sr, n_fft = FRAME_SIZE, hop_length=HOP_SIZE)\n",
    "\n",
    "        #absolute = np.abs(feat)\n",
    "        #feat /= np.max(absolute)\n",
    "        #absolute /= np.max(absolute)\n",
    "        #feat = np.abs(feat)\n",
    "        #row = feat[N,:]\n",
    "        #row = np.abs(row)\n",
    "\n",
    "        #momentum = np.dot(t, absolute)\n",
    "        #momentum/=np.sum(absolute)\n",
    "        #means = np.mean(feat)\n",
    "\n",
    "        feature = np.array([[audio_rms, feat]])\n",
    "        if features[fruit] is not None:\n",
    "            features[fruit] = np.vstack([features[fruit], feature])\n",
    "        else:\n",
    "            features[fruit] = feature\n",
    "# Ploteo\n",
    "plot_features2d(features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Envelope por rms con 512 de hop**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 2000\n",
    "features = dict.fromkeys(fruit_types)\n",
    "split_frequency = 2000\n",
    "\n",
    "# Extracción de características\n",
    "for fruit, group in processed.items():\n",
    "    features[fruit] = None\n",
    "    for audio in group:\n",
    "        signal, sr, duration = load_audio(audio)\n",
    "        audio_rms = np.sqrt(np.mean(signal**2))/np.max(signal)\n",
    "\n",
    "        smoothed = rms(signal)\n",
    "        smoothed = smoothed.reshape(-1,)\n",
    "        smoothed /= np.max(np.abs(smoothed))\n",
    "\n",
    "        feat = np.mean(smoothed)\n",
    "        \n",
    "        feature = np.array([[audio_rms, feat]])\n",
    "        if features[fruit] is not None:\n",
    "            features[fruit] = np.vstack([features[fruit], feature])\n",
    "        else:\n",
    "            features[fruit] = feature\n",
    "# Ploteo\n",
    "plot_features2d(features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 2000\n",
    "features = dict.fromkeys(fruit_types)\n",
    "split_frequency = 2000\n",
    "\n",
    "# Extracción de características\n",
    "for fruit, group in processed.items():\n",
    "    features[fruit] = None\n",
    "    for audio in group:\n",
    "        signal, sr, duration = load_audio(audio)\n",
    "        audio_rms = np.sqrt(np.mean(signal**2))/np.max(signal)\n",
    "\n",
    "        smoothed = rms(signal)\n",
    "        smoothed = smoothed.reshape(-1,)\n",
    "        smoothed /= np.max(np.abs(smoothed))\n",
    "\n",
    "        feat = np.sqrt(np.mean(smoothed**2))\n",
    "        \n",
    "        feature = np.array([[audio_rms, feat]])\n",
    "        if features[fruit] is not None:\n",
    "            features[fruit] = np.vstack([features[fruit], feature])\n",
    "        else:\n",
    "            features[fruit] = feature\n",
    "# Ploteo\n",
    "plot_features2d(features)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Máximo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 2000\n",
    "features = dict.fromkeys(fruit_types)\n",
    "split_frequency = 2000\n",
    "\n",
    "# Extracción de características\n",
    "for fruit, group in processed.items():\n",
    "    features[fruit] = None\n",
    "    for audio in group:\n",
    "        signal, sr, duration = load_audio(audio)\n",
    "        audio_rms = np.sqrt(np.mean(signal**2))/np.max(signal)\n",
    "\n",
    "        smoothed = rms(signal)\n",
    "        smoothed = smoothed.reshape(-1,)\n",
    "\n",
    "        feat = np.max(np.abs(smoothed))\n",
    "        \n",
    "        feature = np.array([[audio_rms, feat]])\n",
    "        if features[fruit] is not None:\n",
    "            features[fruit] = np.vstack([features[fruit], feature])\n",
    "        else:\n",
    "            features[fruit] = feature\n",
    "# Ploteo\n",
    "plot_features2d(features)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Con el mínimo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 2000\n",
    "features = dict.fromkeys(fruit_types)\n",
    "split_frequency = 2000\n",
    "\n",
    "# Extracción de características\n",
    "for fruit, group in processed.items():\n",
    "    features[fruit] = None\n",
    "    for audio in group:\n",
    "        signal, sr, duration = load_audio(audio)\n",
    "        audio_rms = np.sqrt(np.mean(signal**2))/np.max(signal)\n",
    "\n",
    "        smoothed = rms(signal)\n",
    "        smoothed = smoothed.reshape(-1,)\n",
    "\n",
    "        feat = np.min(np.abs(smoothed))\n",
    "        \n",
    "        feature = np.array([[audio_rms, feat]])\n",
    "        if features[fruit] is not None:\n",
    "            features[fruit] = np.vstack([features[fruit], feature])\n",
    "        else:\n",
    "            features[fruit] = feature\n",
    "# Ploteo\n",
    "plot_features2d(features)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Con la varianza. Nuevamente la varianza haciendo su magia cuando la variable  está previamente normalizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 2000\n",
    "features = dict.fromkeys(fruit_types)\n",
    "split_frequency = 2000\n",
    "\n",
    "# Extracción de características\n",
    "for fruit, group in processed.items():\n",
    "    features[fruit] = None\n",
    "    for audio in group:\n",
    "        signal, sr, duration = load_audio(audio)\n",
    "        audio_rms = np.sqrt(np.mean(signal**2))/np.max(signal)\n",
    "\n",
    "        smoothed = rms(signal)\n",
    "        smoothed = smoothed.reshape(-1,)\n",
    "        smoothed /= np.max(np.abs(smoothed))\n",
    "        feat = np.var(np.abs(smoothed))\n",
    "        \n",
    "        feature = np.array([[audio_rms, feat]])\n",
    "        if features[fruit] is not None:\n",
    "            features[fruit] = np.vstack([features[fruit], feature])\n",
    "        else:\n",
    "            features[fruit] = feature\n",
    "# Ploteo\n",
    "plot_features2d(features)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Con la desviación estándar. Lo mismo para la desviación estándar. Se nota como estas dos medidas permiten la separación de las bananas, en suma, cuando se toma la desviación respecto de la media, da mejores resultados en la separación de las bananas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 2000\n",
    "features = dict.fromkeys(fruit_types)\n",
    "split_frequency = 2000\n",
    "\n",
    "# Extracción de características\n",
    "for fruit, group in processed.items():\n",
    "    features[fruit] = None\n",
    "    for audio in group:\n",
    "        signal, sr, duration = load_audio(audio)\n",
    "        audio_rms = np.sqrt(np.mean(signal**2))/np.max(signal)\n",
    "\n",
    "        smoothed = rms(signal)\n",
    "        smoothed = smoothed.reshape(-1,)\n",
    "        smoothed /= np.max(np.abs(smoothed))\n",
    "        feat = np.std(smoothed)\n",
    "        \n",
    "        feature = np.array([[audio_rms, feat]])\n",
    "        if features[fruit] is not None:\n",
    "            features[fruit] = np.vstack([features[fruit], feature])\n",
    "        else:\n",
    "            features[fruit] = feature\n",
    "# Ploteo\n",
    "plot_features2d(features)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Con el momento sin la suma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 2000\n",
    "features = dict.fromkeys(fruit_types)\n",
    "split_frequency = 2000\n",
    "\n",
    "# Extracción de características\n",
    "for fruit, group in processed.items():\n",
    "    features[fruit] = None\n",
    "    for audio in group:\n",
    "        signal, sr, duration = load_audio(audio)\n",
    "        audio_rms = np.sqrt(np.mean(signal**2))/np.max(signal)\n",
    "\n",
    "        smoothed = rms(signal)\n",
    "        smoothed = smoothed.reshape(-1,)\n",
    "        smoothed /= np.max(np.abs(smoothed))\n",
    "        t = time_vector(smoothed, duration)\n",
    "        feat = np.dot(np.abs(smoothed), t)\n",
    "        \n",
    "        feature = np.array([[audio_rms, feat]])\n",
    "        if features[fruit] is not None:\n",
    "            features[fruit] = np.vstack([features[fruit], feature])\n",
    "        else:\n",
    "            features[fruit] = feature\n",
    "# Ploteo\n",
    "plot_features2d(features)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Con la suma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 2000\n",
    "features = dict.fromkeys(fruit_types)\n",
    "split_frequency = 2000\n",
    "\n",
    "# Extracción de características\n",
    "for fruit, group in processed.items():\n",
    "    features[fruit] = None\n",
    "    for audio in group:\n",
    "        signal, sr, duration = load_audio(audio)\n",
    "        audio_rms = np.sqrt(np.mean(signal**2))/np.max(signal)\n",
    "\n",
    "        smoothed = rms(signal)\n",
    "        smoothed = smoothed.reshape(-1,)\n",
    "        smoothed /= np.max(np.abs(smoothed))\n",
    "        t = time_vector(smoothed, duration)\n",
    "        feat = np.dot(np.abs(smoothed), t)/np.sum(np.abs(smoothed))\n",
    "        \n",
    "        feature = np.array([[audio_rms, feat]])\n",
    "        if features[fruit] is not None:\n",
    "            features[fruit] = np.vstack([features[fruit], feature])\n",
    "        else:\n",
    "            features[fruit] = feature\n",
    "# Ploteo\n",
    "plot_features2d(features)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CON EL SMOOTHED ENVELOPE DE HILBERT**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MEDIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 2000\n",
    "features = dict.fromkeys(fruit_types)\n",
    "split_frequency = 2000\n",
    "\n",
    "# Extracción de características\n",
    "for fruit, group in processed.items():\n",
    "    features[fruit] = None\n",
    "    for audio in group:\n",
    "        signal, sr, duration = load_audio(audio)\n",
    "        audio_rms = np.sqrt(np.mean(signal**2))/np.max(signal)\n",
    "\n",
    "        smoothed = smooth_envelope(signal, sr, 45)\n",
    "        smoothed = smoothed.reshape(-1,)\n",
    "        smoothed /= np.max(np.abs(smoothed))\n",
    "\n",
    "        feat = np.mean(smoothed)\n",
    "        \n",
    "        feature = np.array([[audio_rms, feat]])\n",
    "        if features[fruit] is not None:\n",
    "            features[fruit] = np.vstack([features[fruit], feature])\n",
    "        else:\n",
    "            features[fruit] = feature\n",
    "# Ploteo\n",
    "plot_features2d(features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 2000\n",
    "features = dict.fromkeys(fruit_types)\n",
    "split_frequency = 2000\n",
    "\n",
    "# Extracción de características\n",
    "for fruit, group in processed.items():\n",
    "    features[fruit] = None\n",
    "    for audio in group:\n",
    "        signal, sr, duration = load_audio(audio)\n",
    "        audio_rms = np.sqrt(np.mean(signal**2))/np.max(signal)\n",
    "\n",
    "        smoothed = smooth_envelope(signal, sr, 45)\n",
    "        smoothed = smoothed.reshape(-1,)\n",
    "        smoothed /= np.max(np.abs(smoothed))\n",
    "\n",
    "        feat = np.sqrt(np.mean(smoothed**2))\n",
    "        \n",
    "        feature = np.array([[audio_rms, feat]])\n",
    "        if features[fruit] is not None:\n",
    "            features[fruit] = np.vstack([features[fruit], feature])\n",
    "        else:\n",
    "            features[fruit] = feature\n",
    "# Ploteo\n",
    "plot_features2d(features)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MAXIMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 2000\n",
    "features = dict.fromkeys(fruit_types)\n",
    "split_frequency = 2000\n",
    "\n",
    "# Extracción de características\n",
    "for fruit, group in processed.items():\n",
    "    features[fruit] = None\n",
    "    for audio in group:\n",
    "        signal, sr, duration = load_audio(audio)\n",
    "        audio_rms = np.sqrt(np.mean(signal**2))/np.max(signal)\n",
    "\n",
    "        smoothed = smooth_envelope(signal, sr, 45)\n",
    "        smoothed = smoothed.reshape(-1,)\n",
    "\n",
    "        feat = np.max(np.abs(smoothed))\n",
    "        \n",
    "        feature = np.array([[audio_rms, feat]])\n",
    "        if features[fruit] is not None:\n",
    "            features[fruit] = np.vstack([features[fruit], feature])\n",
    "        else:\n",
    "            features[fruit] = feature\n",
    "# Ploteo\n",
    "plot_features2d(features)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MÍNIMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 2000\n",
    "features = dict.fromkeys(fruit_types)\n",
    "split_frequency = 2000\n",
    "\n",
    "# Extracción de características\n",
    "for fruit, group in processed.items():\n",
    "    features[fruit] = None\n",
    "    for audio in group:\n",
    "        signal, sr, duration = load_audio(audio)\n",
    "        audio_rms = np.sqrt(np.mean(signal**2))/np.max(signal)\n",
    "\n",
    "        smoothed = smooth_envelope(signal, sr, 45)\n",
    "        smoothed = smoothed.reshape(-1,)\n",
    "\n",
    "        feat = np.min(np.abs(smoothed))\n",
    "        \n",
    "        feature = np.array([[audio_rms, feat]])\n",
    "        if features[fruit] is not None:\n",
    "            features[fruit] = np.vstack([features[fruit], feature])\n",
    "        else:\n",
    "            features[fruit] = feature\n",
    "# Ploteo\n",
    "plot_features2d(features)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- VARIANZA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 2000\n",
    "features = dict.fromkeys(fruit_types)\n",
    "split_frequency = 2000\n",
    "\n",
    "# Extracción de características\n",
    "for fruit, group in processed.items():\n",
    "    features[fruit] = None\n",
    "    for audio in group:\n",
    "        signal, sr, duration = load_audio(audio)\n",
    "        audio_rms = np.sqrt(np.mean(signal**2))/np.max(signal)\n",
    "\n",
    "        smoothed = smooth_envelope(signal, sr, 45)\n",
    "        smoothed = smoothed.reshape(-1,)\n",
    "        smoothed /= np.max(np.abs(smoothed))\n",
    "        feat = np.var(np.abs(smoothed))\n",
    "        \n",
    "        feature = np.array([[audio_rms, feat]])\n",
    "        if features[fruit] is not None:\n",
    "            features[fruit] = np.vstack([features[fruit], feature])\n",
    "        else:\n",
    "            features[fruit] = feature\n",
    "# Ploteo\n",
    "plot_features2d(features)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Desviación estándar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 2000\n",
    "features = dict.fromkeys(fruit_types)\n",
    "split_frequency = 2000\n",
    "\n",
    "# Extracción de características\n",
    "for fruit, group in processed.items():\n",
    "    features[fruit] = None\n",
    "    for audio in group:\n",
    "        signal, sr, duration = load_audio(audio)\n",
    "        audio_rms = np.sqrt(np.mean(signal**2))/np.max(signal)\n",
    "\n",
    "        smoothed = smooth_envelope(signal, sr, 45)\n",
    "        smoothed = smoothed.reshape(-1,)\n",
    "        smoothed /= np.max(np.abs(smoothed))\n",
    "        feat = np.std(smoothed)/np.mean(smoothed)\n",
    "        \n",
    "        feature = np.array([[audio_rms, feat]])\n",
    "        if features[fruit] is not None:\n",
    "            features[fruit] = np.vstack([features[fruit], feature])\n",
    "        else:\n",
    "            features[fruit] = feature\n",
    "# Ploteo\n",
    "plot_features2d(features)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Con el momento sin la suma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 2000\n",
    "features = dict.fromkeys(fruit_types)\n",
    "split_frequency = 2000\n",
    "\n",
    "# Extracción de características\n",
    "for fruit, group in processed.items():\n",
    "    features[fruit] = None\n",
    "    for audio in group:\n",
    "        signal, sr, duration = load_audio(audio)\n",
    "        audio_rms = np.sqrt(np.mean(signal**2))/np.max(signal)\n",
    "\n",
    "        smoothed = smooth_envelope(signal, sr, 45)\n",
    "        smoothed = smoothed.reshape(-1,)\n",
    "        smoothed /= np.max(np.abs(smoothed))\n",
    "        t = time_vector(smoothed, duration)\n",
    "        feat = np.dot(np.abs(smoothed), t)\n",
    "        \n",
    "        feature = np.array([[audio_rms, feat]])\n",
    "        if features[fruit] is not None:\n",
    "            features[fruit] = np.vstack([features[fruit], feature])\n",
    "        else:\n",
    "            features[fruit] = feature\n",
    "# Ploteo\n",
    "plot_features2d(features)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Con el momento con la suma. Los momentos son muy buenos para separar a las peras jejeje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 2000\n",
    "features = dict.fromkeys(fruit_types)\n",
    "split_frequency = 2000\n",
    "\n",
    "# Extracción de características\n",
    "for fruit, group in processed.items():\n",
    "    features[fruit] = None\n",
    "    for audio in group:\n",
    "        signal, sr, duration = load_audio(audio)\n",
    "        audio_rms = np.sqrt(np.mean(signal**2))/np.max(signal)\n",
    "\n",
    "        smoothed = smooth_envelope(signal, sr, 45)\n",
    "        smoothed = smoothed.reshape(-1,)\n",
    "        smoothed /= np.max(np.abs(smoothed))\n",
    "        t = time_vector(smoothed, duration)\n",
    "        feat = np.dot(np.abs(smoothed), t)/np.sum(np.abs(smoothed))\n",
    "        \n",
    "        feature = np.array([[audio_rms, feat]])\n",
    "        if features[fruit] is not None:\n",
    "            features[fruit] = np.vstack([features[fruit], feature])\n",
    "        else:\n",
    "            features[fruit] = feature\n",
    "# Ploteo\n",
    "plot_features2d(features)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
