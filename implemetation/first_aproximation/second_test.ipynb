{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import butter, filtfilt\n",
    "from scipy.spatial.distance import pdist, cdist\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import soundfile as sf\n",
    "from prettytable import PrettyTable\n",
    "from scipy.signal import hilbert\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.signal import hilbert, butter, filtfilt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DICCIONARIOS CON LAS RUTAS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_types = ['pera', 'banana', 'manzana', 'naranja']\n",
    "fruits = {fruit: [] for fruit in fruit_types}\n",
    "root_dir = '../../dataset'\n",
    "\n",
    "for dirname, _, filenames in os.walk(root_dir):\n",
    "    fruit_type = os.path.basename(dirname)\n",
    "    if fruit_type in fruit_types:\n",
    "        fruits[fruit_type].extend([os.path.join(dirname, filename) for filename in filenames if filename.endswith('.wav')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimed_audio = {fruit: [] for fruit in fruit_types}\n",
    "for dirname, _, filenames in os.walk(root_dir):\n",
    "    trimpath = os.path.basename(dirname)\n",
    "\n",
    "    if trimpath in 'trimed':\n",
    "        fruit_type = os.path.basename(os.path.dirname(dirname))\n",
    "        if fruit_type in fruit_types:\n",
    "            trimed_audio[fruit_type].extend([os.path.join(dirname, filename) for filename in filenames if filename.endswith('.wav')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_audio = {fruit: [] for fruit in fruit_types}\n",
    "for dirname, _, filenames in os.walk(root_dir):\n",
    "    adjustedpath = os.path.basename(dirname)\n",
    "\n",
    "    if adjustedpath in 'adjusted':\n",
    "        fruit_type = os.path.basename(os.path.dirname(dirname))\n",
    "        if fruit_type in fruit_types:\n",
    "            adjusted_audio[fruit_type].extend([os.path.join(dirname, filename) for filename in filenames if filename.endswith('.wav')])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CARACTERISTICAS DEL AUDIO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAME_SIZE = 512 # In the documentation says it's convenient for speech.C\n",
    "HOP_SIZE   = 256"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FUNCIONES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio(audiofile):\n",
    "    test_audio, sr = librosa.load(audiofile, sr = None)\n",
    "    duration = librosa.get_duration(filename=audiofile, sr=sr)\n",
    "    return test_audio, sr, duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_smoothed_envelope(signal, sr, cutoff_frequency = 10.0):\n",
    "    analytic_signal = hilbert(signal)\n",
    "\n",
    "    # Calcular la envolvente de amplitud\n",
    "    amplitude_envelope = np.abs(analytic_signal)\n",
    "\n",
    "    # Aplicar filtro pasa bajos para suavizar la envolvente\n",
    "    nyquist = 0.5 * sr\n",
    "    cutoff = cutoff_frequency / nyquist\n",
    "    b, a = butter(N=6, Wn=cutoff, btype='low', analog=False, output='ba')\n",
    "    \n",
    "    smoothed_envelope = filtfilt(b, a, amplitude_envelope)\n",
    "\n",
    "    return amplitude_envelope, smoothed_envelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(n_mfcc, fruits):\n",
    "    fruit_vectors = dict.fromkeys(fruits.keys())\n",
    "    \n",
    "    for fruit_name, group in fruits.items():\n",
    "        vectors = list()\n",
    "        for fruit in group:\n",
    "            signal, sr, _ = load_audio(fruit)\n",
    "\n",
    "            mfccs = librosa.feature.mfcc(y=signal, n_mfcc=n_mfcc, sr=sr)\n",
    "            delta_mfccs = librosa.feature.delta(mfccs)\n",
    "            delta2_mfccs = librosa.feature.delta(mfccs, order = 2)\n",
    "            \n",
    "            _, smoothed_envelope = calculate_smoothed_envelope(signal, sr, 45)\n",
    "\n",
    "            selected_indices = np.linspace(0, len(smoothed_envelope) - 1, n_mfcc, dtype=int)\n",
    "            smoothed_envelope = smoothed_envelope[selected_indices]\n",
    "            smoothed_envelope = smoothed_envelope.reshape(-1,1)\n",
    "\n",
    "            smoothed_envelope = smoothed_envelope /np.max(np.linalg.norm(smoothed_envelope , axis=0))\n",
    "            mfccs = mfccs/np.max(np.linalg.norm(mfccs, axis=0))\n",
    "            delta_mfccs  = delta_mfccs/np.max(np.linalg.norm(delta_mfccs, axis=0))\n",
    "            delta2_mfccs = delta2_mfccs/np.max(np.linalg.norm(delta2_mfccs, axis=0))\n",
    "\n",
    "            #features =  np.concatenate((delta_mfccs, smoothed_envelope), axis = 1)\n",
    "            features = smoothed_envelope\n",
    "            features = np.mean(features.T, axis = 0)\n",
    "            vectors.append(features.reshape(1,-1))\n",
    "            \n",
    "        fruit_vectors[fruit_name] = np.vstack(vectors)\n",
    "    return fruit_vectors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "los que mas producen diferencia de forma individual son:\n",
    "- el delta\n",
    "- el smoothed(las componentes 4 y 5 cuando son 13 nmfccs)\n",
    "- el cmoothed separa muy bien las manzanas, agrupa ien las bananas y en general anda bien\n",
    "- el deltamfccs separa bien a las peras de lo demas\n",
    "- Se vio que la envolvente es la que mejor resultados da, el problema es que solamente cuando el audio esta trimeado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sphere(vectors):\n",
    "    center = np.mean(vectors, axis = 0)\n",
    "    center = center.reshape(1, -1)\n",
    "    radius = cdist(center, vectors).max()     # Pairwise distance\n",
    "    return radius, center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centers(features):\n",
    "    centers = dict.fromkeys(features.keys())\n",
    "    for fruit, group in features.items():\n",
    "        _, center = get_sphere(group)\n",
    "        centers[fruit] = center\n",
    "    return centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_radiuses(features):\n",
    "    radiuses = dict.fromkeys(features.keys())\n",
    "    for fruit, group in features.items():\n",
    "        radius, _ = get_sphere(group)\n",
    "        radiuses[fruit] = radius\n",
    "    return radiuses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_overlaps(fruit_features):\n",
    "    centers = get_centers(fruit_features)\n",
    "    radiuses = get_radiuses(fruit_features)\n",
    "    overlaps = dict.fromkeys(fruit_features.keys())\n",
    "    \n",
    "    # A dictionary of dictionarys. Keys, the fruit types\n",
    "    for key in overlaps:\n",
    "        # Each dictionary in the dictionary\n",
    "        overlaps[key] = dict.fromkeys(fruit_types)\n",
    "    \n",
    "    for i in range(len(fruit_types)):\n",
    "        for j in range(i + 1, len(fruit_types)):\n",
    "            distancesAB = cdist(centers[fruit_types[i]], fruit_features[fruit_types[j]])\n",
    "            distancesBA = cdist(centers[fruit_types[j]], fruit_features[fruit_types[i]])\n",
    "\n",
    "            mask_distancesAB = distancesAB < radiuses[fruit_types[i]]\n",
    "            mask_distancesBA = distancesBA < radiuses[fruit_types[j]]\n",
    "\n",
    "            numberBinA = np.count_nonzero(mask_distancesAB)\n",
    "            numberAinB = np.count_nonzero(mask_distancesBA)\n",
    "\n",
    "            overlaps[fruit_types[i]][fruit_types[j]] = numberBinA\n",
    "            overlaps[fruit_types[j]][fruit_types[i]] = numberAinB\n",
    "    return overlaps # Each element is the number of vectors of one group in the sphere of another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_components(centers, nc):\n",
    "    pacum = np.zeros((1, centers[fruit_types[0]].shape[1]))\n",
    "    pair_components = dict()\n",
    "    for i in range(len(fruit_types)):\n",
    "        for j in range(i + 1, len(fruit_types)):\n",
    "            dif = centers[fruit_types[i]] - centers[fruit_types[j]]\n",
    "            dist = cdist(centers[fruit_types[i]], centers[fruit_types[j]])\n",
    "            difp = (dif**2)*100/(dist**2)\n",
    "            pair_components[f\"{fruit_types[i]}-{fruit_types[j]}\"]= np.argsort(difp[0])[-nc:]\n",
    "            pacum += difp\n",
    "    index_max = np.argsort(pacum[0])[-nc:]\n",
    "    #return np.sort(index_max)\n",
    "    return index_max, pair_components"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PRINCIPAL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = get_features(5, trimed_audio)\n",
    "overlaps = get_overlaps(features)\n",
    "centers = get_centers(features)\n",
    "components, _ = get_components(centers, 2) \n",
    "radius, _ = get_sphere(np.squeeze(list(centers.values()), axis=1))\n",
    "\n",
    "print(f\"componentes: {components}\")\n",
    "\n",
    "for pair, overlap in overlaps.items():\n",
    "    print(f\"{pair}: {overlap}\")\n",
    "\n",
    "print(f\"radius: {radius}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, group in features.items():\n",
    "    features[name] = group[:, np.sort(components)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole = np.concatenate(list(features.values()), axis=0)\n",
    "\n",
    "#Paso 2: Aplicar PCA para obtener dos componentes principales\n",
    "pca = PCA(n_components = 2)\n",
    "reduced_features = pca.fit_transform(whole)\n",
    "\n",
    "#Paso 3: Crear un diccionario con las matrices reducidas\n",
    "reduced = {}\n",
    "start_idx = 0\n",
    "\n",
    "for fruit, matrix in features.items():\n",
    "    num_rows = matrix.shape[0]\n",
    "    reduced[fruit] = reduced_features[start_idx:start_idx + num_rows, :]\n",
    "    start_idx += num_rows\n",
    "features = reduced"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(training, test, k_n):\n",
    "    X = np.concatenate([v for v in training.values()], axis=0)\n",
    "    y = np.concatenate([[k] * v.shape[0] for k, v in training.items()])\n",
    "\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Crear clasificador KNN\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors = k_n)\n",
    "\n",
    "    # Entrenar el clasificador\n",
    "    knn_classifier.fit(X, y)\n",
    "\n",
    "    # Predecir las etiquetas para los datos de prueba\n",
    "    predicted_fruit = knn_classifier.predict(test)\n",
    "\n",
    "    print(f'La fruta predicha para el nuevo audio es: {predicted_fruit[0]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PLOTEO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2d\n",
    "fig = plt.figure()\n",
    "\n",
    "colors = dict(zip(fruit_types,['green','yellow','red','orange']))\n",
    "center_colors  = dict(zip(fruit_types,['blue','brown','black','cyan']))\n",
    "\n",
    "for fruit, points in features.items():\n",
    "    plt.scatter(points[:, 0], points[:, 1], c = colors[fruit], label=fruit)\n",
    "\n",
    "plt.xlabel('Eje X')\n",
    "plt.ylabel('Eje Y')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3d\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "for fruit, points in features.items():\n",
    "    ax.scatter(points[:, 0], points[:, 1], points[:, 2], c=colors[fruit], marker='o', label=fruit)\n",
    "    #ax.scatter(centers[fruit][:, 0], centers[fruit][:, 1], centers[fruit][:, 2], c=center_colors[fruit], marker='o', label=f\"{fruit}-center\")\n",
    "\n",
    "# configure labels\n",
    "ax.set_xlabel('Eje X')\n",
    "ax.set_ylabel('Eje Y')\n",
    "ax.set_zlabel('Eje Z')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PRUEBA ENVOLVENTES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit = 'pera'\n",
    "indice = 6\n",
    "\n",
    "\n",
    "# Función para cargar la señal de audio y calcular la envolvente\n",
    "def calculate_amplitude_envelope(file_path):\n",
    "    # Cargar la señal de audio\n",
    "    signal, sr = librosa.load(file_path, sr=None)\n",
    "\n",
    "    # Calcular la transformada de Hilbert\n",
    "    analytic_signal = hilbert(signal)\n",
    "\n",
    "    # Calcular la envolvente de amplitud\n",
    "    amplitude_envelope = np.abs(analytic_signal)\n",
    "\n",
    "    return signal, sr, amplitude_envelope\n",
    "\n",
    "# Ruta de tu archivo de audio\n",
    "file_path = fruits[fruit][indice]\n",
    "\n",
    "# Calcular la señal y la envolvente de amplitud\n",
    "original_signal, sr, amplitude_envelope = calculate_amplitude_envelope(file_path)\n",
    "\n",
    "# Crear el gráfico\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Visualizar la señal original\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(np.arange(len(original_signal)) / sr, original_signal)\n",
    "plt.title('Señal Original')\n",
    "plt.xlabel('Tiempo (s)')\n",
    "plt.ylabel('Amplitud')\n",
    "\n",
    "# Visualizar la envolvente de amplitud\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(np.arange(len(amplitude_envelope)) / sr, amplitude_envelope, alpha=0.5)\n",
    "plt.title('Envolvente de Amplitud')\n",
    "plt.xlabel('Tiempo (s)')\n",
    "plt.ylabel('Amplitud')\n",
    "\n",
    "# Ajustar el diseño del gráfico\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import hilbert, butter, filtfilt\n",
    "\n",
    "fruit = 'pera'\n",
    "indice = 6\n",
    "\n",
    "# Función para cargar la señal de audio y calcular la envolvente suavizada\n",
    "def calculate_smoothed_envelope(file_path, cutoff_frequency=10.0):\n",
    "    # Cargar la señal de audio\n",
    "    signal, sr = librosa.load(file_path, sr=None)\n",
    "\n",
    "    # Calcular la transformada de Hilbert\n",
    "    analytic_signal = hilbert(signal)\n",
    "\n",
    "    # Calcular la envolvente de amplitud\n",
    "    amplitude_envelope = np.abs(analytic_signal)\n",
    "\n",
    "    # Aplicar filtro pasa bajos para suavizar la envolvente\n",
    "    nyquist = 0.5 * sr\n",
    "    cutoff = cutoff_frequency / nyquist\n",
    "    b, a = butter(N=6, Wn=cutoff, btype='low', analog=False, output='ba')\n",
    "    print(f\"(b, a): ({b},{a})\")\n",
    "    smoothed_envelope = filtfilt(b, a, amplitude_envelope)\n",
    "\n",
    "    return signal, sr, amplitude_envelope, smoothed_envelope\n",
    "\n",
    "# Ruta de tu archivo de audio\n",
    "file_path = fruits[fruit][indice]\n",
    "\n",
    "# Calcular la señal y las envolventes\n",
    "original_signal, sr, amplitude_envelope, smoothed_envelope = calculate_smoothed_envelope(file_path, 50)\n",
    "\n",
    "# Crear el gráfico\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Visualizar la señal original\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(np.arange(len(original_signal)) / sr, original_signal)\n",
    "plt.title('Señal Original')\n",
    "plt.xlabel('Tiempo (s)')\n",
    "plt.ylabel('Amplitud')\n",
    "\n",
    "# Visualizar la envolvente de amplitud\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(np.arange(len(amplitude_envelope)) / sr, amplitude_envelope, alpha=0.5, label='Envolvente Original')\n",
    "plt.title('Envolvente de Amplitud Original')\n",
    "plt.xlabel('Tiempo (s)')\n",
    "plt.ylabel('Amplitud')\n",
    "plt.legend()\n",
    "\n",
    "# Visualizar la envolvente suavizada\n",
    "print(len(smoothed_envelope))\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(np.arange(len(smoothed_envelope)) / sr, smoothed_envelope, label='Envolvente Suavizada', color='orange')\n",
    "plt.title('Envolvente de Amplitud Suavizada')\n",
    "plt.xlabel('Tiempo (s)')\n",
    "plt.ylabel('Amplitud')\n",
    "plt.legend()\n",
    "\n",
    "# Ajustar el diseño del gráfico\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PRUEBA MFCCS**\n",
    "\n",
    "Se hizo la graficación en función del número de vector de las componentes de mel (13)\n",
    "\n",
    "Se hizo sobre el audio 6 de todos los grupos tanto para el caso original, recortado (35) y ajustado (todos los audios de todos los grupos con la misma duración).\n",
    "\n",
    "Se normalizaron los vectores respecto de la norma euclidea del mas grande de todos a lo largo del audio.\n",
    "\n",
    "Algunas conclusiones que se sacaron de este análisis es que:\n",
    "- Solamente el 1 y 2 coeficientes de mel se separan del resto de los coeficientes para todas las frutas\n",
    "- El resto de los coeficientes se encuentran agrupados cera del cero\n",
    "- Aunque el resto de las componentes se presenten agrupadas se pueden identificar variaciones carácteristicas para cada fruta\n",
    "- Cuando se aplica el ajuste de tiempo por compresión se puede notar que se suaviza la variación de los mfccs (todos) y por lo tanto se pierden las variaciones características de los coeficientes de mel para cada fruta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar la señal de audio\n",
    "fruit = 'naranja'\n",
    "indice = 6\n",
    "audio_path = adjusted_audio[fruit][indice]\n",
    "\n",
    "audio_signal, sr = librosa.load(audio_path, sr=None)\n",
    "\n",
    "# Calcular los MFCCs\n",
    "mfccs = librosa.feature.mfcc(y=audio_signal, sr=sr, n_mfcc=13)\n",
    "\n",
    "# Normalizar cada vector de MFCC según la norma euclidiana\n",
    "mfccs_normalized = mfccs / np.max(np.linalg.norm(mfccs, axis=0))\n",
    "mfccs_normalized = mfccs_normalized.T\n",
    "for i in range(mfccs_normalized.shape[1]):  # Recorrer cada componente\n",
    "    plt.plot(mfccs_normalized[:, i], label=f'{i + 1}')\n",
    "\n",
    "plt.legend()\n",
    "plt.title(f\"Evolución de los MFCCs Normalizados {fruit}\")\n",
    "plt.xlabel('Tiempo (s)')\n",
    "plt.ylabel('Número de Componente MFCC')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PRUEBA CON LAS MEDIAS DE LOS COEFICIENTES DE MEL**\n",
    "Se hizo ahora la comparción de las medias de los mfccs a lo largo de las columnas para un mismo audio (6) para cada grupo de frutas. Tanto para los audios originales, los recortados y los ajustados.\n",
    "\n",
    "Se observo qué:\n",
    "\n",
    "- Las medias no se diferencian notablemente entre las frutas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar la señal de audio\n",
    "fruit = 'naranja'\n",
    "indice = 6\n",
    "audio_path = fruits[fruit][indice]\n",
    "\n",
    "audio_signal, sr = librosa.load(audio_path, sr=None)\n",
    "\n",
    "# Calcular los MFCCs\n",
    "mfccs = librosa.feature.mfcc(y=audio_signal, sr=sr, n_mfcc=13)\n",
    "mfccs = np.mean(mfccs.T, axis = 0)\n",
    "mfccs = mfccs.reshape(-1, 1)\n",
    "mfccs = mfccs/np.linalg.norm(mfccs, axis = 0)\n",
    "\n",
    "plt.plot(mfccs, label=f'{i + 1}')\n",
    "\n",
    "plt.legend()\n",
    "plt.title(f\"Evolución de los MFCCs Normalizados {fruit}\")\n",
    "plt.xlabel('Tiempo (s)')\n",
    "plt.ylabel('Número de Componente MFCC')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**COMPARACIÓN DE CON LOS DELTAS Y LOS DELTASDELTAS**\n",
    "Se hizo lo mismo que al inicio para los mfccs, es decir, la representación de la variación del delta mfccs en funcón del número de componente para todos los grupos de audios para todos los grupos de frutas\n",
    "\n",
    "Se concluyo qué:\n",
    "\n",
    "- Existen diferencias mas notables entre grupos de frutas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar la señal de audio\n",
    "fruit = 'manzana'\n",
    "indice = 6\n",
    "audio_path = fruits[fruit][indice]\n",
    "\n",
    "audio_signal, sr = librosa.load(audio_path, sr=None)\n",
    "\n",
    "# Calcular los MFCCs\n",
    "mfccs = librosa.feature.mfcc(y=audio_signal, sr=sr, n_mfcc=13)\n",
    "delta_mfccs = librosa.feature.delta(mfccs, order = 2)\n",
    "\n",
    "# Normalizar cada vector de MFCC según la norma euclidiana\n",
    "delta_mfccs_normalized = delta_mfccs / np.max(np.linalg.norm(delta_mfccs, axis=0))\n",
    "delta_mfccs_normalized = delta_mfccs_normalized.T\n",
    "\n",
    "for i in range(delta_mfccs_normalized.shape[1]):  # Recorrer cada componente\n",
    "    plt.plot(delta_mfccs_normalized[:, i], label=f'{i + 1}')\n",
    "\n",
    "plt.legend()\n",
    "plt.title(f\"Evolución de los MFCCs Normalizados {fruit}\")\n",
    "plt.xlabel('Tiempo (s)')\n",
    "plt.ylabel('Número de Componente MFCC')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FFT DE LOS DELTAMFFCS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar la señal de audio\n",
    "fruit = 'banana'\n",
    "indice = 6\n",
    "audio_path = adjusted_audio[fruit][indice]\n",
    "\n",
    "audio_signal, sr = librosa.load(audio_path, sr=None)\n",
    "\n",
    "# Calcular los MFCCs\n",
    "mfccs = librosa.feature.mfcc(y=audio_signal, sr=sr, n_mfcc=13)\n",
    "delta_mfccs = librosa.feature.delta(mfccs)\n",
    "\n",
    "# Normalizar cada vector de MFCC según la norma euclidiana\n",
    "delta_mfccs_normalized = delta_mfccs / np.max(np.linalg.norm(delta_mfccs, axis=0))\n",
    "\n",
    "t = np.linspace(0, 1, delta_mfccs_normalized.shape[1])\n",
    "ts = 1/(len(t)-1)\n",
    "fs = 1/ts\n",
    "\n",
    "fft_result = np.fft.fft(delta_mfccs_normalized, axis=1)\n",
    "fft_freqs = np.fft.fftfreq(len(t), 1/fs)\n",
    "\n",
    "# Graficar los resultados\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i in range(len(delta_mfccs_normalized)):\n",
    "    plt.subplot(len(delta_mfccs_normalized), 2, 2 * i + 2)\n",
    "    plt.bar(fft_freqs, np.abs(fft_result[i, :]), width=fs/len(t), align='center')\n",
    "\n",
    "#plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MEDIA DE LOS DELTA MFCCS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar la señal de audio\n",
    "fruit = 'naranja'\n",
    "indice = 6\n",
    "audio_path = fruits[fruit][indice]\n",
    "\n",
    "audio_signal, sr = librosa.load(audio_path, sr=None)\n",
    "\n",
    "# Calcular los MFCCs\n",
    "mfccs = librosa.feature.mfcc(y=audio_signal, sr=sr, n_mfcc=13)\n",
    "mfccs = librosa.feature.delta(mfccs, order = 2)\n",
    "mfccs = np.mean(mfccs.T, axis = 0)\n",
    "mfccs = mfccs.reshape(-1, 1)\n",
    "mfccs = mfccs/np.linalg.norm(mfccs, axis = 0)\n",
    "\n",
    "plt.plot(mfccs, label=f'{i + 1}')\n",
    "\n",
    "plt.legend()\n",
    "plt.title(f\"Evolución de los MFCCs Normalizados {fruit}\")\n",
    "plt.xlabel('Tiempo (s)')\n",
    "plt.ylabel('Número de Componente MFCC')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
