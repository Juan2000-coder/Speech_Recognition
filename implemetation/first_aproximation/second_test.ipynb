{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import butter, filtfilt\n",
    "from scipy.spatial.distance import pdist, cdist\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import soundfile as sf\n",
    "from prettytable import PrettyTable\n",
    "from scipy.signal import hilbert\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DICCIONARIOS CON LAS RUTAS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_types = ['pera', 'banana', 'manzana', 'naranja']\n",
    "fruits = {fruit: [] for fruit in fruit_types}\n",
    "root_dir = '../../dataset'\n",
    "\n",
    "for dirname, _, filenames in os.walk(root_dir):\n",
    "    fruit_type = os.path.basename(dirname)\n",
    "    if fruit_type in fruit_types:\n",
    "        fruits[fruit_type].extend([os.path.join(dirname, filename) for filename in filenames if filename.endswith('.wav')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimed_audio = {fruit: [] for fruit in fruit_types}\n",
    "for dirname, _, filenames in os.walk(root_dir):\n",
    "    trimpath = os.path.basename(dirname)\n",
    "\n",
    "    if trimpath in 'trimed':\n",
    "        fruit_type = os.path.basename(os.path.dirname(dirname))\n",
    "        if fruit_type in fruit_types:\n",
    "            trimed_audio[fruit_type].extend([os.path.join(dirname, filename) for filename in filenames if filename.endswith('.wav')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_audio = {fruit: [] for fruit in fruit_types}\n",
    "for dirname, _, filenames in os.walk(root_dir):\n",
    "    adjustedpath = os.path.basename(dirname)\n",
    "\n",
    "    if adjustedpath in 'adjusted':\n",
    "        fruit_type = os.path.basename(os.path.dirname(dirname))\n",
    "        if fruit_type in fruit_types:\n",
    "            adjusted_audio[fruit_type].extend([os.path.join(dirname, filename) for filename in filenames if filename.endswith('.wav')])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CARACTERISTICAS DEL AUDIO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAME_SIZE = 512 # In the documentation says it's convenient for speech.C\n",
    "HOP_SIZE   = 256"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FUNCIONES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio(audiofile):\n",
    "    test_audio, sr = librosa.load(audiofile, sr = None)\n",
    "    duration = librosa.get_duration(filename=audiofile, sr=sr)\n",
    "    return test_audio, sr, duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(n_mfcc, fruits):\n",
    "    fruit_vectors = dict.fromkeys(fruits.keys())\n",
    "    \n",
    "    for fruit_name, group in fruits.items():\n",
    "        vectors = list()\n",
    "        for fruit in group:\n",
    "            signal, sr, _ = load_audio(fruit)\n",
    "            mfccs = librosa.feature.mfcc(y=signal, n_mfcc=n_mfcc, sr=sr)\n",
    "            delta_mfccs = librosa.feature.delta(mfccs)\n",
    "            delta2_mfccs = librosa.feature.delta(mfccs, order = 2)\n",
    "            \n",
    "            features =  np.concatenate((mfccs, delta_mfccs, delta2_mfccs), axis = 1)\n",
    "            features = np.mean(features.T, axis = 0)\n",
    "            vectors.append(features.reshape(1,-1))\n",
    "            \n",
    "        fruit_vectors[fruit_name] = np.vstack(vectors)\n",
    "    return fruit_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sphere(vectors):\n",
    "    center = np.mean(vectors, axis = 0)\n",
    "    center = center.reshape(1, -1)\n",
    "    radius = cdist(center, vectors).max()     # Pairwise distance\n",
    "    return radius, center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centers(features):\n",
    "    centers = dict.fromkeys(features.keys())\n",
    "    for fruit, group in features.items():\n",
    "        _, center = get_sphere(group)\n",
    "        centers[fruit] = center\n",
    "    return centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_radiuses(features):\n",
    "    radiuses = dict.fromkeys(features.keys())\n",
    "    for fruit, group in features.items():\n",
    "        radius, _ = get_sphere(group)\n",
    "        radiuses[fruit] = radius\n",
    "    return radiuses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_overlaps(fruit_features):\n",
    "    centers = get_centers(fruit_features)\n",
    "    radiuses = get_radiuses(fruit_features)\n",
    "    overlaps = dict.fromkeys(fruit_features.keys())\n",
    "    \n",
    "    # A dictionary of dictionarys. Keys, the fruit types\n",
    "    for key in overlaps:\n",
    "        # Each dictionary in the dictionary\n",
    "        overlaps[key] = dict.fromkeys(fruit_types)\n",
    "    \n",
    "    for i in range(len(fruit_types)):\n",
    "        for j in range(i + 1, len(fruit_types)):\n",
    "            distancesAB = cdist(centers[fruit_types[i]], fruit_features[fruit_types[j]])\n",
    "            distancesBA = cdist(centers[fruit_types[j]], fruit_features[fruit_types[i]])\n",
    "\n",
    "            mask_distancesAB = distancesAB < radiuses[fruit_types[i]]\n",
    "            mask_distancesBA = distancesBA < radiuses[fruit_types[j]]\n",
    "\n",
    "            numberBinA = np.count_nonzero(mask_distancesAB)\n",
    "            numberAinB = np.count_nonzero(mask_distancesBA)\n",
    "\n",
    "            overlaps[fruit_types[i]][fruit_types[j]] = numberBinA\n",
    "            overlaps[fruit_types[j]][fruit_types[i]] = numberAinB\n",
    "    return overlaps # Each element is the number of vectors of one group in the sphere of another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_components(centers, nc):\n",
    "    pacum = np.zeros((1, centers[fruit_types[0]].shape[1]))\n",
    "    pair_components = dict()\n",
    "    for i in range(len(fruit_types)):\n",
    "        for j in range(i + 1, len(fruit_types)):\n",
    "            dif = centers[fruit_types[i]] - centers[fruit_types[j]]\n",
    "            dist = cdist(centers[fruit_types[i]], centers[fruit_types[j]])\n",
    "            difp = (dif**2)*100/(dist**2)\n",
    "            pair_components[f\"{fruit_types[i]}-{fruit_types[j]}\"]= np.argsort(difp[0])[-nc:]\n",
    "            pacum += difp\n",
    "    index_max = np.argsort(pacum[0])[-nc:]\n",
    "    #return np.sort(index_max)\n",
    "    return index_max, pair_components"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PRINCIPAL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = get_features(13, trimed_audio)\n",
    "overlaps = get_overlaps(features)\n",
    "centers = get_centers(features)\n",
    "components, _ = get_components(centers, 2) \n",
    "radius, _ = get_sphere(np.squeeze(list(centers.values()), axis=1))\n",
    "\n",
    "print(f\"componentes: {components}\")\n",
    "\n",
    "for pair, overlap in overlaps.items():\n",
    "    print(f\"{pair}: {overlap}\")\n",
    "\n",
    "print(f\"radius: {radius}\")\n",
    "for name, group in features.items():\n",
    "    features[name] = group[:, np.sort(components)]\n",
    "#whole = np.concatenate(list(features.values()), axis=0)\n",
    "\n",
    "# Paso 2: Aplicar PCA para obtener dos componentes principales\n",
    "#pca = PCA(n_components = 2)\n",
    "#reduced_features = pca.fit_transform(whole)\n",
    "\n",
    "# Paso 3: Crear un diccionario con las matrices reducidas\n",
    "#reduced = {}\n",
    "#start_idx = 0\n",
    "\n",
    "#for fruit, matrix in features.items():\n",
    "#    num_rows = matrix.shape[0]\n",
    "#    reduced[fruit] = reduced_features[start_idx:start_idx + num_rows, :]\n",
    "#    start_idx += num_rows\n",
    "#features = reduced"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(training, test, k_n):\n",
    "    X = np.concatenate([v for v in training.values()], axis=0)\n",
    "    y = np.concatenate([[k] * v.shape[0] for k, v in training.items()])\n",
    "\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Crear clasificador KNN\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors = k_n)\n",
    "\n",
    "    # Entrenar el clasificador\n",
    "    knn_classifier.fit(X, y)\n",
    "\n",
    "    # Predecir las etiquetas para los datos de prueba\n",
    "    predicted_fruit = knn_classifier.predict(test)\n",
    "\n",
    "    print(f'La fruta predicha para el nuevo audio es: {predicted_fruit[0]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PLOTEO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "colors = dict(zip(fruit_types,['green','yellow','red','orange']))\n",
    "center_colors  = dict(zip(fruit_types,['blue','brown','black','cyan']))\n",
    "\n",
    "for fruit, points in features.items():\n",
    "    plt.scatter(points[:, 0], points[:, 1], c = colors[fruit], label=fruit)\n",
    "\n",
    "plt.xlabel('Eje X')\n",
    "plt.ylabel('Eje Y')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PRUEBA ENVOLVENTES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit = 'pera'\n",
    "indice = 6\n",
    "\n",
    "\n",
    "# Función para cargar la señal de audio y calcular la envolvente\n",
    "def calculate_amplitude_envelope(file_path):\n",
    "    # Cargar la señal de audio\n",
    "    signal, sr = librosa.load(file_path, sr=None)\n",
    "\n",
    "    # Calcular la transformada de Hilbert\n",
    "    analytic_signal = hilbert(signal)\n",
    "\n",
    "    # Calcular la envolvente de amplitud\n",
    "    amplitude_envelope = np.abs(analytic_signal)\n",
    "\n",
    "    return signal, sr, amplitude_envelope\n",
    "\n",
    "# Ruta de tu archivo de audio\n",
    "file_path = fruits[fruit][indice]\n",
    "\n",
    "# Calcular la señal y la envolvente de amplitud\n",
    "original_signal, sr, amplitude_envelope = calculate_amplitude_envelope(file_path)\n",
    "\n",
    "# Crear el gráfico\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Visualizar la señal original\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(np.arange(len(original_signal)) / sr, original_signal)\n",
    "plt.title('Señal Original')\n",
    "plt.xlabel('Tiempo (s)')\n",
    "plt.ylabel('Amplitud')\n",
    "\n",
    "# Visualizar la envolvente de amplitud\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(np.arange(len(amplitude_envelope)) / sr, amplitude_envelope, alpha=0.5)\n",
    "plt.title('Envolvente de Amplitud')\n",
    "plt.xlabel('Tiempo (s)')\n",
    "plt.ylabel('Amplitud')\n",
    "\n",
    "# Ajustar el diseño del gráfico\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import hilbert, butter, filtfilt\n",
    "\n",
    "fruit = 'pera'\n",
    "indice = 6\n",
    "\n",
    "# Función para cargar la señal de audio y calcular la envolvente suavizada\n",
    "def calculate_smoothed_envelope(file_path, cutoff_frequency=10.0):\n",
    "    # Cargar la señal de audio\n",
    "    signal, sr = librosa.load(file_path, sr=None)\n",
    "\n",
    "    # Calcular la transformada de Hilbert\n",
    "    analytic_signal = hilbert(signal)\n",
    "\n",
    "    # Calcular la envolvente de amplitud\n",
    "    amplitude_envelope = np.abs(analytic_signal)\n",
    "\n",
    "    # Aplicar filtro pasa bajos para suavizar la envolvente\n",
    "    nyquist = 0.5 * sr\n",
    "    cutoff = cutoff_frequency / nyquist\n",
    "    b, a = butter(N=6, Wn=cutoff, btype='low', analog=False, output='ba')\n",
    "    print(f\"(b, a): ({b},{a})\")\n",
    "    smoothed_envelope = filtfilt(b, a, amplitude_envelope)\n",
    "\n",
    "    return signal, sr, amplitude_envelope, smoothed_envelope\n",
    "\n",
    "# Ruta de tu archivo de audio\n",
    "file_path = fruits[fruit][indice]\n",
    "\n",
    "# Calcular la señal y las envolventes\n",
    "original_signal, sr, amplitude_envelope, smoothed_envelope = calculate_smoothed_envelope(file_path, 50)\n",
    "\n",
    "# Crear el gráfico\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Visualizar la señal original\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(np.arange(len(original_signal)) / sr, original_signal)\n",
    "plt.title('Señal Original')\n",
    "plt.xlabel('Tiempo (s)')\n",
    "plt.ylabel('Amplitud')\n",
    "\n",
    "# Visualizar la envolvente de amplitud\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(np.arange(len(amplitude_envelope)) / sr, amplitude_envelope, alpha=0.5, label='Envolvente Original')\n",
    "plt.title('Envolvente de Amplitud Original')\n",
    "plt.xlabel('Tiempo (s)')\n",
    "plt.ylabel('Amplitud')\n",
    "plt.legend()\n",
    "\n",
    "# Visualizar la envolvente suavizada\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(np.arange(len(smoothed_envelope)) / sr, smoothed_envelope, label='Envolvente Suavizada', color='orange')\n",
    "plt.title('Envolvente de Amplitud Suavizada')\n",
    "plt.xlabel('Tiempo (s)')\n",
    "plt.ylabel('Amplitud')\n",
    "plt.legend()\n",
    "\n",
    "# Ajustar el diseño del gráfico\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
