{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import pdist, cdist\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import soundfile as sf\n",
    "from prettytable import PrettyTable\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.signal import hilbert, butter, filtfilt, medfilt, lfilter, wiener, convolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_types = ['pera', 'banana', 'manzana', 'naranja']\n",
    "audios = {fruit: [] for fruit in fruit_types}\n",
    "root_dir = '../../dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dirname, _, filenames in os.walk(root_dir):\n",
    "    fruit_type = os.path.basename(dirname)\n",
    "    if fruit_type in fruit_types:\n",
    "        audios[fruit_type].extend([os.path.join(dirname, filename) for filename in filenames if filename.endswith('.wav')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = {fruit: [] for fruit in fruit_types}\n",
    "\n",
    "for dirname, _, filenames in os.walk(root_dir):\n",
    "    path = os.path.basename(dirname)\n",
    "    if path == 'processed':\n",
    "        fruit_type = os.path.basename(os.path.dirname(dirname))\n",
    "        if fruit_type in fruit_types:\n",
    "            processed[fruit_type].extend([os.path.join(dirname, filename) for filename in filenames if filename.endswith('.wav')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAME_SIZE = 1024 # In the documentation says it's convenient for speech.C\n",
    "HOP_SIZE   = int(FRAME_SIZE/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio(audiofile):\n",
    "    test_audio, sr = librosa.load(audiofile, sr = None)\n",
    "    duration = librosa.get_duration(filename=audiofile, sr=sr)\n",
    "    return test_audio, sr, duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_vector(signal, duration):\n",
    "    return np.linspace(0, duration, len(signal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rms(signal):\n",
    "    return librosa.feature.rms(y=signal, frame_length = FRAME_SIZE, hop_length = HOP_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(signal):\n",
    "    peak = np.max(signal)\n",
    "    signal/=peak\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def low_pass_filter(signal, sr, cutoff_frequency = 5000):\n",
    "    nyquist = 0.5 * sr\n",
    "    cutoff = cutoff_frequency / nyquist\n",
    "    b, a = butter(N=6, Wn=cutoff, btype='low', analog=False, output='ba')\n",
    "    filtered = lfilter(b, a, signal)\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def band_pass_filter(signal, sr, low_cutoff, high_cutoff):\n",
    "    b, a = butter(N=3, Wn = [low_cutoff, high_cutoff], btype='band', fs=sr)\n",
    "    return lfilter(b, a, signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wiener_filter(signal, noise = 0.9):\n",
    "    filtered = wiener(signal, noise = noise)\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def envelope(signal):\n",
    "    analytic_signal = hilbert(signal)\n",
    "    return np.abs(analytic_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_envelope(signal, sr, cutoff_frequency=50.0):\n",
    "    return low_pass_filter(envelope(signal), sr, cutoff_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_split_frequency_bin(split_frequency, sample_rate, num_frequency_bins):\n",
    "    \"\"\"Infer the frequency bin associated to a given split frequency.\"\"\"\n",
    "    \n",
    "    frequency_range = sample_rate / 2\n",
    "    frequency_delta_per_bin = frequency_range / num_frequency_bins\n",
    "    split_frequency_bin = math.floor(split_frequency / frequency_delta_per_bin)\n",
    "    return int(split_frequency_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def band_energy_ratio(spectrogram, split_frequency, sample_rate):\n",
    "    \"\"\"Calculate band energy ratio with a given split frequency.\"\"\"\n",
    "    \n",
    "    split_frequency_bin = calculate_split_frequency_bin(split_frequency, sample_rate, len(spectrogram[0]))\n",
    "    band_energy_ratio = []\n",
    "    \n",
    "    # calculate power spectrogram\n",
    "    power_spectrogram = np.abs(spectrogram) ** 2\n",
    "    power_spectrogram = power_spectrogram.T\n",
    "    \n",
    "    # calculate BER value for each frame\n",
    "    for frame in power_spectrogram:\n",
    "        sum_power_low_frequencies = frame[:split_frequency_bin].sum()\n",
    "        sum_power_high_frequencies = frame[split_frequency_bin:].sum()\n",
    "        band_energy_ratio_current_frame = sum_power_low_frequencies / sum_power_high_frequencies\n",
    "        band_energy_ratio.append(band_energy_ratio_current_frame)\n",
    "    \n",
    "    return np.array(band_energy_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2d\n",
    "def plot_features2d(features):\n",
    "    fig = plt.figure()\n",
    "    colors = dict(zip(fruit_types,['green','yellow','red','orange']))\n",
    "    \n",
    "\n",
    "    for fruit, points in features.items():\n",
    "        plt.scatter(points[:, 0], points[:, 1], c = colors[fruit], label=fruit)\n",
    "\n",
    "    plt.xlabel('Eje X')\n",
    "    plt.ylabel('Eje Y')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3d\n",
    "def plot_features3d(features):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    colors = dict(zip(fruit_types,['green','yellow','red','orange']))\n",
    "\n",
    "    for fruit, points in features.items():\n",
    "        ax.scatter(points[:, 0], points[:, 1], points[:, 2], c=colors[fruit], marker='o', label=fruit)\n",
    "        \n",
    "    ax.set_xlabel('Eje X')\n",
    "    ax.set_ylabel('Eje Y')\n",
    "    ax.set_zlabel('Eje Z')\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PRIMERA APROXIMACIÃ“N. BASTANTE BIEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juan\\AppData\\Local\\Temp\\ipykernel_3788\\1587896153.py:3: FutureWarning: get_duration() keyword argument 'filename' has been renamed to 'path' in version 0.10.0.\n",
      "\tThis alias will be removed in version 1.0.\n",
      "  duration = librosa.get_duration(filename=audiofile, sr=sr)\n"
     ]
    }
   ],
   "source": [
    "# Features extraction\n",
    "features = dict.fromkeys(fruit_types)\n",
    "split_frequency = 3000\n",
    "cuton = 20\n",
    "cutoff = 8500\n",
    "n_mfcc = 4\n",
    "\n",
    "for fruit, audios in processed.items():\n",
    "    features[fruit] = None\n",
    "    \n",
    "    for audio in audios:\n",
    "        # Load the audio signal\n",
    "        signal, sr, duration = load_audio(audio)\n",
    "\n",
    "        # Empty row of features\n",
    "        feature = np.empty((1, 0))\n",
    "\n",
    "        # Calculate the rms\n",
    "        audio_rms = np.sqrt(np.mean(signal**2))/np.max(signal)\n",
    "        feat = audio_rms\n",
    "        feature = np.append(feature, audio_rms)\n",
    "\n",
    "        # BER min\n",
    "        spec = librosa.stft(signal, n_fft = FRAME_SIZE, hop_length = HOP_SIZE)\n",
    "        BER  = band_energy_ratio(spec, split_frequency, sr)\n",
    "        feat = np.min(BER)\n",
    "        #feature = np.append(feature, feat)\n",
    "\n",
    "        # Centroid\n",
    "        centroid = librosa.feature.spectral_centroid(y=signal, sr=sr, n_fft=FRAME_SIZE, hop_length=HOP_SIZE)[0]\n",
    "        centroid /= np.max(np.abs(centroid))\n",
    "        # Varnz\n",
    "        feat = np.var(centroid)\n",
    "        #feature = np.append(feature, feat)\n",
    "        # std\n",
    "        feat = np.std(centroid)/np.mean(centroid)\n",
    "        feature = np.append(feature, feat)\n",
    "\n",
    "        # Envelope RMS\n",
    "        smoothed = rms(signal)\n",
    "        smoothed = smoothed.reshape(-1,)\n",
    "        smoothed /= np.max(np.abs(smoothed))\n",
    "        # varnz\n",
    "        feat = np.var(smoothed)\n",
    "        #feature = np.append(feature, feat)\n",
    "        #std\n",
    "        feat = np.std(smoothed)/np.mean(smoothed)\n",
    "        feature = np.append(feature, feat)\n",
    "        #momentum\n",
    "        t = time_vector(smoothed, duration)\n",
    "        feat = np.dot(smoothed, t)/np.sum(smoothed)\n",
    "        feature = np.append(feature, feat)\n",
    "\n",
    "        #ZCR\n",
    "        filtered = band_pass_filter(signal, sr, cuton, cutoff)\n",
    "        zcr = librosa.feature.zero_crossing_rate(filtered, frame_length=FRAME_SIZE, hop_length=HOP_SIZE)[0]\n",
    "        zcr /= np.max(np.abs(zcr))\n",
    "        #mean\n",
    "        feat = np.mean(zcr)\n",
    "        feature = np.append(feature, feat)\n",
    "        #maximum\n",
    "        feat = np.max(zcr)\n",
    "        #feature = np.append(feature, feat)\n",
    "        #varnz\n",
    "        feat = np.var(zcr)\n",
    "        #feature = np.append(feature, feat)\n",
    "        #std\n",
    "        feat = np.std(zcr)/np.mean(zcr)\n",
    "        feature = np.append(feature, feat)\n",
    "\n",
    "        #MFCCS\n",
    "        mfccs = librosa.feature.mfcc(y = signal, sr=sr, n_mfcc = n_mfcc, n_fft = FRAME_SIZE, hop_length = HOP_SIZE)\n",
    "        #maximum\n",
    "        feat = np.max(mfccs, axis = 1)\n",
    "        feat = feat[3]\n",
    "        feature = np.append(feature, feat)\n",
    "        \n",
    "        mfccs /= np.max(np.abs(mfccs), axis = 1, keepdims=True)\n",
    "\n",
    "        #vrnz\n",
    "        feat = np.var(mfccs, axis = 1)\n",
    "        feat = feat[1]\n",
    "        #feature = np.append(feature, feat)\n",
    "        #std\n",
    "        feat = np.std(mfccs, axis = 1)/np.mean(mfccs, axis = 1)\n",
    "        feat = feat[1]\n",
    "        #feature = np.append(feature, feat)\n",
    "        #momentum\n",
    "        frames = range(mfccs.shape[1])\n",
    "        t = librosa.frames_to_time(frames, sr=sr, n_fft = FRAME_SIZE, hop_length = HOP_SIZE)\n",
    "        feat = np.dot(mfccs, t)/np.sum(mfccs, axis = 1)\n",
    "        feat = feat[0]\n",
    "        #feature = np.append(feature, feat)\n",
    "\n",
    "        #hilbert envelope\n",
    "        env = smooth_envelope(signal, sr, 45)\n",
    "        selected = np.linspace(0, len(env) - 1, 30, dtype=int)\n",
    "        env = env[selected]\n",
    "        env = env.reshape(-1,1)\n",
    "        feat = env[11]\n",
    "        feature = np.append(feature, feat)\n",
    "        feat = env[12]\n",
    "        feature = np.append(feature, feat)\n",
    "\n",
    "        if features[fruit] is not None:\n",
    "            features[fruit] = np.vstack([features[fruit], feature])\n",
    "        else:\n",
    "            features[fruit] = feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features extraction\n",
    "features = dict.fromkeys(fruit_types)\n",
    "split_frequency = 3000\n",
    "cuton = 20\n",
    "cutoff = 8500\n",
    "n_mfcc = 4\n",
    "\n",
    "for fruit, audios in processed.items():\n",
    "    features[fruit] = None\n",
    "    \n",
    "    for audio in audios:\n",
    "        # Load the audio signal\n",
    "        signal, sr, duration = load_audio(audio)\n",
    "\n",
    "        # Empty row of features\n",
    "        feature = np.empty((1, 0))\n",
    "\n",
    "        # Calculate the rms\n",
    "        audio_rms = np.sqrt(np.mean(signal**2))/np.max(signal)\n",
    "        feat = audio_rms\n",
    "        feature = np.append(feature, audio_rms)\n",
    "\n",
    "        # BER min\n",
    "        spec = librosa.stft(signal, n_fft = FRAME_SIZE, hop_length = HOP_SIZE)\n",
    "        BER  = band_energy_ratio(spec, split_frequency, sr)\n",
    "        feat = np.min(BER)\n",
    "        #feature = np.append(feature, feat)\n",
    "\n",
    "        # Centroid\n",
    "        centroid = librosa.feature.spectral_centroid(y=signal, sr=sr, n_fft=FRAME_SIZE, hop_length=HOP_SIZE)[0]\n",
    "        centroid /= np.max(np.abs(centroid))\n",
    "        # Varnz\n",
    "        feat = np.var(centroid)\n",
    "        #feature = np.append(feature, feat)\n",
    "        # std\n",
    "        feat = np.std(centroid)/np.mean(centroid)\n",
    "        feature = np.append(feature, feat)\n",
    "\n",
    "        # Envelope RMS\n",
    "        smoothed = rms(signal)\n",
    "        smoothed = smoothed.reshape(-1,)\n",
    "        smoothed /= np.max(np.abs(smoothed))\n",
    "        # varnz\n",
    "        feat = np.var(smoothed)\n",
    "        #feature = np.append(feature, feat)\n",
    "        #std\n",
    "        feat = np.std(smoothed)/np.mean(smoothed)\n",
    "        feature = np.append(feature, feat)\n",
    "        #momentum\n",
    "        t = time_vector(smoothed, duration)\n",
    "        feat = np.dot(smoothed, t)/np.sum(smoothed)\n",
    "        feature = np.append(feature, feat)\n",
    "\n",
    "        #ZCR\n",
    "        filtered = band_pass_filter(signal, sr, cuton, cutoff)\n",
    "        zcr = librosa.feature.zero_crossing_rate(filtered, frame_length=FRAME_SIZE, hop_length=HOP_SIZE)[0]\n",
    "        zcr /= np.max(np.abs(zcr))\n",
    "        #mean\n",
    "        feat = np.mean(zcr)\n",
    "        feature = np.append(feature, feat)\n",
    "        #maximum\n",
    "        feat = np.max(zcr)\n",
    "        #feature = np.append(feature, feat)\n",
    "        #varnz\n",
    "        feat = np.var(zcr)\n",
    "        #feature = np.append(feature, feat)\n",
    "        #std\n",
    "        feat = np.std(zcr)/np.mean(zcr)\n",
    "        feature = np.append(feature, feat)\n",
    "\n",
    "        #MFCCS\n",
    "        mfccs = librosa.feature.mfcc(y = signal, sr=sr, n_mfcc = n_mfcc, n_fft = FRAME_SIZE, hop_length = HOP_SIZE)\n",
    "        #maximum\n",
    "        feat = np.max(mfccs, axis = 1)\n",
    "        feat = feat[3]\n",
    "        feature = np.append(feature, feat)\n",
    "        \n",
    "        mfccs /= np.max(np.abs(mfccs), axis = 1, keepdims=True)\n",
    "\n",
    "        #vrnz\n",
    "        feat = np.var(mfccs, axis = 1)\n",
    "        feat = feat[1]\n",
    "        #feature = np.append(feature, feat)\n",
    "        #std\n",
    "        feat = np.std(mfccs, axis = 1)/np.mean(mfccs, axis = 1)\n",
    "        feat = feat[1]\n",
    "        #feature = np.append(feature, feat)\n",
    "        #momentum\n",
    "        frames = range(mfccs.shape[1])\n",
    "        t = librosa.frames_to_time(frames, sr=sr, n_fft = FRAME_SIZE, hop_length = HOP_SIZE)\n",
    "        feat = np.dot(mfccs, t)/np.sum(mfccs, axis = 1)\n",
    "        feat = feat[0]\n",
    "        #feature = np.append(feature, feat)\n",
    "\n",
    "        #hilbert envelope\n",
    "        env = smooth_envelope(signal, sr, 45)\n",
    "        selected = np.linspace(0, len(env) - 1, 30, dtype=int)\n",
    "        env = env[selected]\n",
    "        env = env.reshape(-1,1)\n",
    "        feat = env[11]\n",
    "        feature = np.append(feature, feat)\n",
    "        feat = env[12]\n",
    "        feature = np.append(feature, feat)\n",
    "\n",
    "        if features[fruit] is not None:\n",
    "            features[fruit] = np.vstack([features[fruit], feature])\n",
    "        else:\n",
    "            features[fruit] = feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA\n",
    "whole = np.concatenate(list(features.values()), axis=0)\n",
    "\n",
    "#Paso 2: Aplicar PCA para obtener dos componentes principales\n",
    "pca = PCA(n_components = 2)\n",
    "reduced_features = pca.fit_transform(whole)\n",
    "\n",
    "#Paso 3: Crear un diccionario con las matrices reducidas\n",
    "reduced = {}\n",
    "start_idx = 0\n",
    "\n",
    "for fruit, matrix in features.items():\n",
    "    num_rows = matrix.shape[0]\n",
    "    reduced[fruit] = reduced_features[start_idx:start_idx + num_rows, :]\n",
    "    start_idx += num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_features2d(reduced)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
