{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import pdist, cdist\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import soundfile as sf\n",
    "from prettytable import PrettyTable\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.signal import hilbert, butter, filtfilt, medfilt, lfilter, wiener, convolve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_types = ['pera', 'banana', 'manzana', 'naranja']\n",
    "audios = {fruit: [] for fruit in fruit_types}\n",
    "root_dir = '../../dataset'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dirname, _, filenames in os.walk(root_dir):\n",
    "    fruit_type = os.path.basename(dirname)\n",
    "    if fruit_type in fruit_types:\n",
    "        audios[fruit_type].extend([os.path.join(dirname, filename) for filename in filenames if filename.endswith('.wav')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = {fruit: [] for fruit in fruit_types}\n",
    "\n",
    "for dirname, _, filenames in os.walk(root_dir):\n",
    "    path = os.path.basename(dirname)\n",
    "    if path == 'processed':\n",
    "        fruit_type = os.path.basename(os.path.dirname(dirname))\n",
    "        if fruit_type in fruit_types:\n",
    "            processed[fruit_type].extend([os.path.join(dirname, filename) for filename in filenames if filename.endswith('.wav')])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAME_SIZE = 1024 # In the documentation says it's convenient for speech.C\n",
    "HOP_SIZE   = int(FRAME_SIZE/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio(audiofile):\n",
    "    test_audio, sr = librosa.load(audiofile, sr = None)\n",
    "    duration = librosa.get_duration(filename=audiofile, sr=sr)\n",
    "    return test_audio, sr, duration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_vector(signal, duration):\n",
    "    return np.linspace(0, duration, len(signal))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rms(signal):\n",
    "    return librosa.feature.rms(y=signal, frame_length = FRAME_SIZE, hop_length = HOP_SIZE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(signal):\n",
    "    peak = np.max(signal)\n",
    "    signal/=peak\n",
    "    return signal\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def low_pass_filter(signal, sr, cutoff_frequency = 5000):\n",
    "    nyquist = 0.5 * sr\n",
    "    cutoff = cutoff_frequency / nyquist\n",
    "    b, a = butter(N=6, Wn=cutoff, btype='low', analog=False, output='ba')\n",
    "    filtered = lfilter(b, a, signal)\n",
    "    return filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def band_pass_filter(signal, sr, low_cutoff, high_cutoff):\n",
    "    b, a = butter(N=3, Wn = [low_cutoff, high_cutoff], btype='band', fs=sr)\n",
    "    return lfilter(b, a, signal)\n",
    "def wiener_filter(signal, noise = 0.9):\n",
    "    filtered = wiener(signal, noise = noise)\n",
    "    return filtered\n",
    "def envelope(signal):\n",
    "    analytic_signal = hilbert(signal)\n",
    "    return np.abs(analytic_signal)\n",
    "\n",
    "def smooth_envelope(signal, sr, cutoff_frequency=50.0):\n",
    "    return low_pass_filter(envelope(signal), sr, cutoff_frequency)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2d\n",
    "def plot_features2d(features):\n",
    "    fig = plt.figure()\n",
    "    colors = dict(zip(fruit_types,['green','yellow','red','orange']))\n",
    "    \n",
    "\n",
    "    for fruit, points in features.items():\n",
    "        plt.scatter(points[:, 0], points[:, 1], c = colors[fruit], label=fruit)\n",
    "\n",
    "    plt.xlabel('Eje X')\n",
    "    plt.ylabel('Eje Y')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cutoff = 2000\n",
    "features = dict.fromkeys(fruit_types)\n",
    "split_frequency = 2000\n",
    "\n",
    "# Extracción de características\n",
    "for fruit, group in processed.items():\n",
    "    features[fruit] = None\n",
    "    for audio in group:\n",
    "        signal, sr, duration = load_audio(audio)\n",
    "        audio_rms = np.sqrt(np.mean(signal**2))/np.max(signal)\n",
    "\n",
    "        #spec = librosa.stft(signal, n_fft = FRAME_SIZE, hop_length = HOP_SIZE)\n",
    "        #BER  = band_energy_ratio(spec, split_frequency, sr)\n",
    "        #BER /= np.max(BER)\n",
    "        #feat = np.mean(BER)\n",
    "\n",
    "        #centroidal = librosa.feature.spectral_centroid(y=signal, sr=sr, n_fft=FRAME_SIZE, hop_length=HOP_SIZE)[0]\n",
    "        #centroidal /= np.max(centroidal)\n",
    "        #centroidal = np.mean(centroidal)\n",
    "        #smoothed = rms(signal)\n",
    "        #smoothed = smoothed.reshape(-1,)\n",
    "        #rms_smoothed = np.mean(smoothed)/np.max(smoothed)\n",
    "        #filtered = low_pass_filter(signal, sr, cutoff)\n",
    "        #feat = librosa.feature.zero_crossing_rate(signal, frame_length=FRAME_SIZE, hop_length=HOP_SIZE)[0]\n",
    "        #max = np.max(zcr)\n",
    "        #flux = spectral_flux(filtered)\n",
    "        #max = np.max(flux)\n",
    "        #flux /= max\n",
    "        #flux = np.mean(flux)\n",
    "        #roll_off = librosa.feature.spectral_rolloff(y=signal, sr=sr, n_fft=FRAME_SIZE, hop_length=HOP_SIZE, roll_percent=0.85)[0]\n",
    "        #max = np.max(roll_off)\n",
    "        #roll_off /= max\n",
    "        #roll_off = np.mean(roll_off)\n",
    "        #smoothed /= np.max(smoothed)\n",
    "        #N = 1\n",
    "        #feat = librosa.feature.mfcc(y = signal, sr=sr, n_mfcc = 5, n_fft = FRAME_SIZE, hop_length = HOP_SIZE)\n",
    "        #feat = librosa.feature.delta(feat, order = 3)\n",
    "\n",
    "        #frames = range(len(feat))\n",
    "        #t = librosa.frames_to_time(frames, sr=sr, n_fft = FRAME_SIZE, hop_length=HOP_SIZE)\n",
    "\n",
    "        #absolute = np.abs(feat)\n",
    "        #feat /= np.max(absolute)\n",
    "        #absolute /= np.max(absolute)\n",
    "        #feat = np.abs(feat)\n",
    "        #row = feat[N,:]\n",
    "        #row = np.abs(row)\n",
    "\n",
    "        #momentum = np.dot(t, absolute)\n",
    "        #momentum/=np.sum(absolute)\n",
    "        #means = np.mean(feat)\n",
    "\n",
    "        feature = np.array([[audio_rms, feat]])\n",
    "        if features[fruit] is not None:\n",
    "            features[fruit] = np.vstack([features[fruit], feature])\n",
    "        else:\n",
    "            features[fruit] = feature\n",
    "# Ploteo\n",
    "plot_features2d(features)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MFCC**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 6500\n",
    "cuton = 50\n",
    "features = dict.fromkeys(fruit_types)\n",
    "split_frequency = 200\n",
    "\n",
    "\n",
    "# Extracción de características\n",
    "for fruit, group in processed.items():\n",
    "    features[fruit] = None\n",
    "    for audio in group:\n",
    "        signal, sr, duration = load_audio(audio)\n",
    "        audio_rms = np.sqrt(np.mean(signal**2))/np.max(signal)\n",
    "\n",
    "        mfccs = librosa.feature.mfcc(y = signal, sr=sr, n_mfcc = 30, n_fft = FRAME_SIZE, hop_length = HOP_SIZE)\n",
    "        mfccs /= np.max(np.abs(mfccs), axis = 1, keepdims=True)\n",
    "        feat = np.mean(mfccs, axis = 1)\n",
    "        componente = 26\n",
    "        feature = np.array([[audio_rms, feat[componente]]])\n",
    "        if features[fruit] is not None:\n",
    "            features[fruit] = np.vstack([features[fruit], feature])\n",
    "        else:\n",
    "            features[fruit] = feature\n",
    "# Ploteo\n",
    "plot_features2d(features)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RMS. Mejor la media que el RMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 6500\n",
    "cuton = 50\n",
    "features = dict.fromkeys(fruit_types)\n",
    "split_frequency = 200\n",
    "\n",
    "\n",
    "# Extracción de características\n",
    "componnte = 0\n",
    "while componente < 30:\n",
    "    for fruit, group in processed.items():\n",
    "        features[fruit] = None\n",
    "        for audio in group:\n",
    "            signal, sr, duration = load_audio(audio)\n",
    "            audio_rms = np.sqrt(np.mean(signal**2))/np.max(signal)\n",
    "\n",
    "            mfccs = librosa.feature.mfcc(y = signal, sr=sr, n_mfcc = 30, n_fft = FRAME_SIZE, hop_length = HOP_SIZE)\n",
    "            mfccs /= np.max(np.abs(mfccs), axis = 1, keepdims=True)\n",
    "            feat = np.sqrt(np.mean(mfccs**2, axis=1))\n",
    "\n",
    "\n",
    "            feature = np.array([[audio_rms, feat[componente]]])\n",
    "            if features[fruit] is not None:\n",
    "                features[fruit] = np.vstack([features[fruit], feature])\n",
    "            else:\n",
    "                features[fruit] = feature\n",
    "    # Ploteo\n",
    "    plot_features2d(features)\n",
    "    input()\n",
    "    componente += 1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Máximo. En la componente 3 se separan las manzanas de las peras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 6500\n",
    "cuton = 50\n",
    "features = dict.fromkeys(fruit_types)\n",
    "split_frequency = 200\n",
    "\n",
    "\n",
    "# Extracción de características\n",
    "componente = 0\n",
    "while componente < 30:\n",
    "    for fruit, group in processed.items():\n",
    "        features[fruit] = None\n",
    "        for audio in group:\n",
    "            signal, sr, duration = load_audio(audio)\n",
    "            audio_rms = np.sqrt(np.mean(signal**2))/np.max(signal)\n",
    "\n",
    "            mfccs = librosa.feature.mfcc(y = signal, sr=sr, n_mfcc = 30, n_fft = FRAME_SIZE, hop_length = HOP_SIZE)\n",
    "            feat = np.max(mfccs, axis = 1)\n",
    "            mfccs /= np.max(np.abs(mfccs), axis = 1, keepdims=True)\n",
    "\n",
    "            feature = np.array([[audio_rms, feat[componente]]])\n",
    "            if features[fruit] is not None:\n",
    "                features[fruit] = np.vstack([features[fruit], feature])\n",
    "            else:\n",
    "                features[fruit] = feature\n",
    "    # Ploteo\n",
    "    plot_features2d(features)\n",
    "    input()\n",
    "    componente += 1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mínimo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 6500\n",
    "cuton = 50\n",
    "features = dict.fromkeys(fruit_types)\n",
    "split_frequency = 200\n",
    "\n",
    "\n",
    "# Extracción de características\n",
    "componente = 0\n",
    "while componente < 30:\n",
    "    for fruit, group in processed.items():\n",
    "        features[fruit] = None\n",
    "        for audio in group:\n",
    "            signal, sr, duration = load_audio(audio)\n",
    "            audio_rms = np.sqrt(np.mean(signal**2))/np.max(signal)\n",
    "\n",
    "            mfccs = librosa.feature.mfcc(y = signal, sr=sr, n_mfcc = 30, n_fft = FRAME_SIZE, hop_length = HOP_SIZE)\n",
    "            feat = np.min(mfccs, axis = 1)\n",
    "            mfccs /= np.max(np.abs(mfccs), axis = 1, keepdims=True)\n",
    "\n",
    "            feature = np.array([[audio_rms, feat[componente]]])\n",
    "            if features[fruit] is not None:\n",
    "                features[fruit] = np.vstack([features[fruit], feature])\n",
    "            else:\n",
    "                features[fruit] = feature\n",
    "    # Ploteo\n",
    "    plot_features2d(features)\n",
    "    input()\n",
    "    componente += 1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Varianza. La componente 1 mas o menos separa las bananas de las naranjas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 6500\n",
    "cuton = 50\n",
    "features = dict.fromkeys(fruit_types)\n",
    "split_frequency = 200\n",
    "\n",
    "\n",
    "# Extracción de características\n",
    "componente = 0\n",
    "while componente < 30:\n",
    "    for fruit, group in processed.items():\n",
    "        features[fruit] = None\n",
    "        for audio in group:\n",
    "            signal, sr, duration = load_audio(audio)\n",
    "            audio_rms = np.sqrt(np.mean(signal**2))/np.max(signal)\n",
    "\n",
    "            mfccs = librosa.feature.mfcc(y = signal, sr=sr, n_mfcc = 30, n_fft = FRAME_SIZE, hop_length = HOP_SIZE)\n",
    "            mfccs /= np.max(np.abs(mfccs), axis = 1, keepdims=True)\n",
    "            feat = np.var(mfccs, axis = 1)\n",
    "\n",
    "            feature = np.array([[audio_rms, feat[componente]]])\n",
    "            if features[fruit] is not None:\n",
    "                features[fruit] = np.vstack([features[fruit], feature])\n",
    "            else:\n",
    "                features[fruit] = feature\n",
    "    # Ploteo\n",
    "    plot_features2d(features)\n",
    "    input()\n",
    "    componente += 1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Desviación estándar. Lo mismo que la varianza respecto de la componente 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[39m# Ploteo\u001b[39;00m\n\u001b[0;32m     26\u001b[0m plot_features2d(features)\n\u001b[1;32m---> 27\u001b[0m \u001b[39minput\u001b[39;49m()\n\u001b[0;32m     28\u001b[0m componente \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py:1251\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1249\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1250\u001b[0m     \u001b[39mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1251\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_input_request(\n\u001b[0;32m   1252\u001b[0m     \u001b[39mstr\u001b[39;49m(prompt),\n\u001b[0;32m   1253\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parent_ident[\u001b[39m\"\u001b[39;49m\u001b[39mshell\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m   1254\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_parent(\u001b[39m\"\u001b[39;49m\u001b[39mshell\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1255\u001b[0m     password\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m   1256\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py:1295\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1292\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1293\u001b[0m     \u001b[39m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1294\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mInterrupted by user\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1295\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1296\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m   1297\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog\u001b[39m.\u001b[39mwarning(\u001b[39m\"\u001b[39m\u001b[39mInvalid Message:\u001b[39m\u001b[39m\"\u001b[39m, exc_info\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "cutoff = 6500\n",
    "cuton = 50\n",
    "features = dict.fromkeys(fruit_types)\n",
    "split_frequency = 200\n",
    "\n",
    "\n",
    "# Extracción de características\n",
    "componente = 0\n",
    "while componente < 30:\n",
    "    for fruit, group in processed.items():\n",
    "        features[fruit] = None\n",
    "        for audio in group:\n",
    "            signal, sr, duration = load_audio(audio)\n",
    "            audio_rms = np.sqrt(np.mean(signal**2))/np.max(signal)\n",
    "\n",
    "            mfccs = librosa.feature.mfcc(y = signal, sr=sr, n_mfcc = 30, n_fft = FRAME_SIZE, hop_length = HOP_SIZE)\n",
    "            mfccs /= np.max(np.abs(mfccs), axis = 1, keepdims=True)\n",
    "            feat = np.std(mfccs, axis = 1)/np.mean(mfccs, axis = 1)\n",
    "\n",
    "            feature = np.array([[audio_rms, feat[componente]]])\n",
    "            if features[fruit] is not None:\n",
    "                features[fruit] = np.vstack([features[fruit], feature])\n",
    "            else:\n",
    "                features[fruit] = feature\n",
    "    # Ploteo\n",
    "    plot_features2d(features)\n",
    "    input()\n",
    "    componente += 1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Con el momento sin la suma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 6500\n",
    "cuton = 50\n",
    "features = dict.fromkeys(fruit_types)\n",
    "split_frequency = 200\n",
    "\n",
    "\n",
    "# Extracción de características\n",
    "componente = 0\n",
    "while componente < 30:\n",
    "    for fruit, group in processed.items():\n",
    "        features[fruit] = None\n",
    "        for audio in group:\n",
    "            signal, sr, duration = load_audio(audio)\n",
    "            audio_rms = np.sqrt(np.mean(signal**2))/np.max(signal)\n",
    "\n",
    "            mfccs = librosa.feature.mfcc(y = signal, sr=sr, n_mfcc = 30, n_fft = FRAME_SIZE, hop_length = HOP_SIZE)\n",
    "            mfccs /= np.max(np.abs(mfccs), axis = 1, keepdims=True)\n",
    "            frames = range(mfccs.shape[1])\n",
    "\n",
    "            t = librosa.frames_to_time(frames, sr=sr, n_fft = FRAME_SIZE, hop_length = HOP_SIZE)\n",
    "            feat = np.dot(mfccs, t)\n",
    "\n",
    "            feature = np.array([[audio_rms, feat[componente]]])\n",
    "            if features[fruit] is not None:\n",
    "                features[fruit] = np.vstack([features[fruit], feature])\n",
    "            else:\n",
    "                features[fruit] = feature\n",
    "    # Ploteo\n",
    "    plot_features2d(features)\n",
    "    input()\n",
    "    componente += 1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Con el momento con suma. Buena separación de las peras respecto de las demas con la componente 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 6500\n",
    "cuton = 50\n",
    "features = dict.fromkeys(fruit_types)\n",
    "split_frequency = 200\n",
    "\n",
    "\n",
    "# Extracción de características\n",
    "componente = 0\n",
    "while componente < 30:\n",
    "    for fruit, group in processed.items():\n",
    "        features[fruit] = None\n",
    "        for audio in group:\n",
    "            signal, sr, duration = load_audio(audio)\n",
    "            audio_rms = np.sqrt(np.mean(signal**2))/np.max(signal)\n",
    "\n",
    "            mfccs = librosa.feature.mfcc(y = signal, sr=sr, n_mfcc = 30, n_fft = FRAME_SIZE, hop_length = HOP_SIZE)\n",
    "            mfccs /= np.max(np.abs(mfccs), axis = 1, keepdims=True)\n",
    "            frames = range(mfccs.shape[1])\n",
    "\n",
    "            t = librosa.frames_to_time(frames, sr=sr, n_fft = FRAME_SIZE, hop_length = HOP_SIZE)\n",
    "            feat = np.dot(np.abs(mfccs), t)/np.sum(np.abs(mfccs), axis = 1)\n",
    "\n",
    "            feature = np.array([[audio_rms, feat[componente]]])\n",
    "            if features[fruit] is not None:\n",
    "                features[fruit] = np.vstack([features[fruit], feature])\n",
    "            else:\n",
    "                features[fruit] = feature\n",
    "    # Ploteo\n",
    "    plot_features2d(features)\n",
    "    input()\n",
    "    componente += 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
